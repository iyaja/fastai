<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Layers</title>
    <meta name="generator" content="VuePress 1.5.4">
    
    <meta name="description" content="Welcome to fastai">
    <link rel="preload" href="/fastai/assets/css/0.styles.24b54ae9.css" as="style"><link rel="preload" href="/fastai/assets/js/app.e4c088e4.js" as="script"><link rel="preload" href="/fastai/assets/js/2.f1c4f916.js" as="script"><link rel="preload" href="/fastai/assets/js/29.7b21b9fd.js" as="script"><link rel="prefetch" href="/fastai/assets/js/10.99994145.js"><link rel="prefetch" href="/fastai/assets/js/11.08687312.js"><link rel="prefetch" href="/fastai/assets/js/12.40b88a98.js"><link rel="prefetch" href="/fastai/assets/js/13.83861397.js"><link rel="prefetch" href="/fastai/assets/js/14.3a1586b8.js"><link rel="prefetch" href="/fastai/assets/js/15.1cbd093c.js"><link rel="prefetch" href="/fastai/assets/js/16.c850565b.js"><link rel="prefetch" href="/fastai/assets/js/17.9c3f07b2.js"><link rel="prefetch" href="/fastai/assets/js/18.db37b5bb.js"><link rel="prefetch" href="/fastai/assets/js/19.c91272fe.js"><link rel="prefetch" href="/fastai/assets/js/20.a9c5f90d.js"><link rel="prefetch" href="/fastai/assets/js/21.e40307f7.js"><link rel="prefetch" href="/fastai/assets/js/22.8fcdc465.js"><link rel="prefetch" href="/fastai/assets/js/23.14fb4a2d.js"><link rel="prefetch" href="/fastai/assets/js/24.720b52ea.js"><link rel="prefetch" href="/fastai/assets/js/25.7912d1b1.js"><link rel="prefetch" href="/fastai/assets/js/26.366239e0.js"><link rel="prefetch" href="/fastai/assets/js/27.6db2df9e.js"><link rel="prefetch" href="/fastai/assets/js/28.ffbcb114.js"><link rel="prefetch" href="/fastai/assets/js/3.6e2ab6c3.js"><link rel="prefetch" href="/fastai/assets/js/30.248393fd.js"><link rel="prefetch" href="/fastai/assets/js/31.b22a56a0.js"><link rel="prefetch" href="/fastai/assets/js/32.85f7da41.js"><link rel="prefetch" href="/fastai/assets/js/33.e44ef8ee.js"><link rel="prefetch" href="/fastai/assets/js/34.9ce56e10.js"><link rel="prefetch" href="/fastai/assets/js/35.4bdc5816.js"><link rel="prefetch" href="/fastai/assets/js/36.67e5f7d9.js"><link rel="prefetch" href="/fastai/assets/js/37.36c20575.js"><link rel="prefetch" href="/fastai/assets/js/38.06c462ff.js"><link rel="prefetch" href="/fastai/assets/js/39.749b6672.js"><link rel="prefetch" href="/fastai/assets/js/4.a083dd6e.js"><link rel="prefetch" href="/fastai/assets/js/40.c732859b.js"><link rel="prefetch" href="/fastai/assets/js/41.4474ab47.js"><link rel="prefetch" href="/fastai/assets/js/42.5ee2fc2f.js"><link rel="prefetch" href="/fastai/assets/js/43.cc635513.js"><link rel="prefetch" href="/fastai/assets/js/44.152c8da5.js"><link rel="prefetch" href="/fastai/assets/js/45.4cff1d71.js"><link rel="prefetch" href="/fastai/assets/js/46.85dce95d.js"><link rel="prefetch" href="/fastai/assets/js/47.59fb5617.js"><link rel="prefetch" href="/fastai/assets/js/48.f20ef06e.js"><link rel="prefetch" href="/fastai/assets/js/49.9625880a.js"><link rel="prefetch" href="/fastai/assets/js/5.bb68e855.js"><link rel="prefetch" href="/fastai/assets/js/50.b2e6dee9.js"><link rel="prefetch" href="/fastai/assets/js/51.267442e2.js"><link rel="prefetch" href="/fastai/assets/js/52.10494ddd.js"><link rel="prefetch" href="/fastai/assets/js/53.093941a1.js"><link rel="prefetch" href="/fastai/assets/js/54.fbc03694.js"><link rel="prefetch" href="/fastai/assets/js/55.0b1efc19.js"><link rel="prefetch" href="/fastai/assets/js/56.5f3c1da5.js"><link rel="prefetch" href="/fastai/assets/js/57.a3e942a9.js"><link rel="prefetch" href="/fastai/assets/js/58.d3ded5e3.js"><link rel="prefetch" href="/fastai/assets/js/59.ec1d3156.js"><link rel="prefetch" href="/fastai/assets/js/6.f6c9602c.js"><link rel="prefetch" href="/fastai/assets/js/60.37aa0b8a.js"><link rel="prefetch" href="/fastai/assets/js/61.ef622343.js"><link rel="prefetch" href="/fastai/assets/js/62.e733d0f9.js"><link rel="prefetch" href="/fastai/assets/js/63.a3aa571a.js"><link rel="prefetch" href="/fastai/assets/js/64.8b06642f.js"><link rel="prefetch" href="/fastai/assets/js/65.97cf2dfa.js"><link rel="prefetch" href="/fastai/assets/js/66.7f97711c.js"><link rel="prefetch" href="/fastai/assets/js/67.31ee059f.js"><link rel="prefetch" href="/fastai/assets/js/68.d013d2de.js"><link rel="prefetch" href="/fastai/assets/js/69.50b9f11d.js"><link rel="prefetch" href="/fastai/assets/js/7.c1cdf251.js"><link rel="prefetch" href="/fastai/assets/js/70.1b6f8370.js"><link rel="prefetch" href="/fastai/assets/js/71.8c3557b5.js"><link rel="prefetch" href="/fastai/assets/js/72.2d857b7b.js"><link rel="prefetch" href="/fastai/assets/js/73.0be86c71.js"><link rel="prefetch" href="/fastai/assets/js/74.a9279ff6.js"><link rel="prefetch" href="/fastai/assets/js/75.f6ce5fb3.js"><link rel="prefetch" href="/fastai/assets/js/8.be08f3ee.js"><link rel="prefetch" href="/fastai/assets/js/9.209ff10c.js">
    <link rel="stylesheet" href="/fastai/assets/css/0.styles.24b54ae9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/fastai/" class="home-link router-link-active"><img src="https://images.exxactcorp.com/CMS/landing-page/resource-center/supported-software/logo/Deep-Learning/fastai-logo.png" alt="" class="logo"> <!----></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Getting Started" class="dropdown-title"><span class="title">Getting Started</span> <span class="arrow down"></span></button> <button type="button" aria-label="Getting Started" class="mobile-dropdown-title"><span class="title">Getting Started</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><!----> <a href="/fastai/quick_start.html" class="nav-link">
  Quick Start
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tutorials" class="dropdown-title"><span class="title">Tutorials</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tutorials" class="mobile-dropdown-title"><span class="title">Tutorials</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/overview.html" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><h4>
          Beginners
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/vision.html" class="nav-link">
  Vision Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/text.html" class="nav-link">
  Text Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/tabular.html" class="nav-link">
  Tabular Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/colab.html" class="nav-link">
  Colab Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Intermediate
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/datablock.html" class="nav-link">
  Data Block Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/imagenette.html" class="nav-link">
  Imagenette Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/pets.html" class="nav-link">
  Pets Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/transformers.html" class="nav-link">
  Transformers Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/wikitext.html" class="nav-link">
  Wikitext Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Advanced
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/siamese.html" class="nav-link">
  Siamese Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/dev-setup.html" class="nav-link">
  Developer Guide
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Training" class="dropdown-title"><span class="title">Training</span> <span class="arrow down"></span></button> <button type="button" aria-label="Training" class="mobile-dropdown-title"><span class="title">Training</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/training/learner.html" class="nav-link">
  Training Loop
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/optimizer.html" class="nav-link">
  Optimizer
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/metrics.html" class="nav-link">
  Metrics
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/interpret.html" class="nav-link">
  Interpretation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/distributed.html" class="nav-link">
  Distributed
</a></li><li class="dropdown-item"><h4>
          Callbacks
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/callback/core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/schedule.html" class="nav-link">
  Schedulers
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/hook.html" class="nav-link">
  Hooks and callbacks
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/fp16.html" class="nav-link">
  Mixed precision
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/mixup.html" class="nav-link">
  Mixup
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/cutmix.html" class="nav-link">
  Cutmix
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/tracker.html" class="nav-link">
  Tracker
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/training.html" class="nav-link">
  Training
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/rnn.html" class="nav-link">
  RNN
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/data.html" class="nav-link">
  Data
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/progress.html" class="nav-link">
  Progress
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Data" class="dropdown-title"><span class="title">Data</span> <span class="arrow down"></span></button> <button type="button" aria-label="Data" class="mobile-dropdown-title"><span class="title">Data</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/data/block.html" class="nav-link">
  Data Blocks
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/transforms.html" class="nav-link">
  Data Transforms
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/external.html" class="nav-link">
  Data External
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/core.html" class="nav-link">
  Data Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/load.html" class="nav-link">
  DataLoaders
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Core" class="dropdown-title"><span class="title">Core</span> <span class="arrow down"></span></button> <button type="button" aria-label="Core" class="mobile-dropdown-title"><span class="title">Core</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/torch_core.html" class="nav-link">
  PyTorch Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/layers.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  Layers
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Vision" class="dropdown-title"><span class="title">Vision</span> <span class="arrow down"></span></button> <button type="button" aria-label="Vision" class="mobile-dropdown-title"><span class="title">Vision</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/vision/learner.html" class="nav-link">
  Vision Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/augment.html" class="nav-link">
  Vision Data Augmentation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/data.html" class="nav-link">
  Vision Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/core.html" class="nav-link">
  Vision Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/utils.html" class="nav-link">
  Vision Utils
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/widgets.html" class="nav-link">
  Vision Widgets
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/vision/models.xresnet.html" class="nav-link">
  XResNet
</a></li><li class="dropdown-subitem"><a href="/fastai/vision/models.unet.html" class="nav-link">
  UNet
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Text" class="dropdown-title"><span class="title">Text</span> <span class="arrow down"></span></button> <button type="button" aria-label="Text" class="mobile-dropdown-title"><span class="title">Text</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/text/core.html" class="nav-link">
  Text Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/data.html" class="nav-link">
  Text Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/learner.html" class="nav-link">
  Text Learner
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/text/models.core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.awdlstm.html" class="nav-link">
  AWD LSTM
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.qrnn.html" class="nav-link">
  QRNN
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tabular" class="dropdown-title"><span class="title">Tabular</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tabular" class="mobile-dropdown-title"><span class="title">Tabular</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tabular/core.html" class="nav-link">
  Tabular Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/data.html" class="nav-link">
  Tabular Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/learner.html" class="nav-link">
  Tabular Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/model.html" class="nav-link">
  Tabular Model
</a></li><li class="dropdown-item"><!----> <a href="/fastai/collab.html" class="nav-link">
  Collab
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Medical" class="dropdown-title"><span class="title">Medical</span> <span class="arrow down"></span></button> <button type="button" aria-label="Medical" class="mobile-dropdown-title"><span class="title">Medical</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/medical/imaging.html" class="nav-link">
  Medical imagery
</a></li><li class="dropdown-item"><!----> <a href="/fastai/medical/text.html" class="nav-link">
  Medical text
</a></li></ul></div></div> <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Getting Started" class="dropdown-title"><span class="title">Getting Started</span> <span class="arrow down"></span></button> <button type="button" aria-label="Getting Started" class="mobile-dropdown-title"><span class="title">Getting Started</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><!----> <a href="/fastai/quick_start.html" class="nav-link">
  Quick Start
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tutorials" class="dropdown-title"><span class="title">Tutorials</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tutorials" class="mobile-dropdown-title"><span class="title">Tutorials</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/overview.html" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><h4>
          Beginners
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/vision.html" class="nav-link">
  Vision Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/text.html" class="nav-link">
  Text Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/tabular.html" class="nav-link">
  Tabular Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/colab.html" class="nav-link">
  Colab Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Intermediate
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/datablock.html" class="nav-link">
  Data Block Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/imagenette.html" class="nav-link">
  Imagenette Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/pets.html" class="nav-link">
  Pets Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/transformers.html" class="nav-link">
  Transformers Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/wikitext.html" class="nav-link">
  Wikitext Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Advanced
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/siamese.html" class="nav-link">
  Siamese Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/dev-setup.html" class="nav-link">
  Developer Guide
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Training" class="dropdown-title"><span class="title">Training</span> <span class="arrow down"></span></button> <button type="button" aria-label="Training" class="mobile-dropdown-title"><span class="title">Training</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/training/learner.html" class="nav-link">
  Training Loop
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/optimizer.html" class="nav-link">
  Optimizer
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/metrics.html" class="nav-link">
  Metrics
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/interpret.html" class="nav-link">
  Interpretation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/distributed.html" class="nav-link">
  Distributed
</a></li><li class="dropdown-item"><h4>
          Callbacks
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/callback/core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/schedule.html" class="nav-link">
  Schedulers
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/hook.html" class="nav-link">
  Hooks and callbacks
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/fp16.html" class="nav-link">
  Mixed precision
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/mixup.html" class="nav-link">
  Mixup
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/cutmix.html" class="nav-link">
  Cutmix
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/tracker.html" class="nav-link">
  Tracker
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/training.html" class="nav-link">
  Training
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/rnn.html" class="nav-link">
  RNN
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/data.html" class="nav-link">
  Data
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/progress.html" class="nav-link">
  Progress
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Data" class="dropdown-title"><span class="title">Data</span> <span class="arrow down"></span></button> <button type="button" aria-label="Data" class="mobile-dropdown-title"><span class="title">Data</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/data/block.html" class="nav-link">
  Data Blocks
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/transforms.html" class="nav-link">
  Data Transforms
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/external.html" class="nav-link">
  Data External
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/core.html" class="nav-link">
  Data Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/load.html" class="nav-link">
  DataLoaders
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Core" class="dropdown-title"><span class="title">Core</span> <span class="arrow down"></span></button> <button type="button" aria-label="Core" class="mobile-dropdown-title"><span class="title">Core</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/torch_core.html" class="nav-link">
  PyTorch Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/layers.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  Layers
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Vision" class="dropdown-title"><span class="title">Vision</span> <span class="arrow down"></span></button> <button type="button" aria-label="Vision" class="mobile-dropdown-title"><span class="title">Vision</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/vision/learner.html" class="nav-link">
  Vision Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/augment.html" class="nav-link">
  Vision Data Augmentation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/data.html" class="nav-link">
  Vision Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/core.html" class="nav-link">
  Vision Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/utils.html" class="nav-link">
  Vision Utils
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/widgets.html" class="nav-link">
  Vision Widgets
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/vision/models.xresnet.html" class="nav-link">
  XResNet
</a></li><li class="dropdown-subitem"><a href="/fastai/vision/models.unet.html" class="nav-link">
  UNet
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Text" class="dropdown-title"><span class="title">Text</span> <span class="arrow down"></span></button> <button type="button" aria-label="Text" class="mobile-dropdown-title"><span class="title">Text</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/text/core.html" class="nav-link">
  Text Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/data.html" class="nav-link">
  Text Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/learner.html" class="nav-link">
  Text Learner
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/text/models.core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.awdlstm.html" class="nav-link">
  AWD LSTM
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.qrnn.html" class="nav-link">
  QRNN
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tabular" class="dropdown-title"><span class="title">Tabular</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tabular" class="mobile-dropdown-title"><span class="title">Tabular</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tabular/core.html" class="nav-link">
  Tabular Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/data.html" class="nav-link">
  Tabular Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/learner.html" class="nav-link">
  Tabular Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/model.html" class="nav-link">
  Tabular Model
</a></li><li class="dropdown-item"><!----> <a href="/fastai/collab.html" class="nav-link">
  Collab
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Medical" class="dropdown-title"><span class="title">Medical</span> <span class="arrow down"></span></button> <button type="button" aria-label="Medical" class="mobile-dropdown-title"><span class="title">Medical</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/medical/imaging.html" class="nav-link">
  Medical imagery
</a></li><li class="dropdown-item"><!----> <a href="/fastai/medical/text.html" class="nav-link">
  Medical text
</a></li></ul></div></div> <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Layers</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/fastai/layers.html#basic-manipulations-and-resize" class="sidebar-link">Basic manipulations and resize</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#pooling-layers" class="sidebar-link">Pooling layers</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#batchnorm-layers" class="sidebar-link">BatchNorm layers</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#inits" class="sidebar-link">Inits</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#convolutions" class="sidebar-link">Convolutions</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#fastai-loss-functions" class="sidebar-link">fastai loss functions</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#embeddings" class="sidebar-link">Embeddings</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#self-attention" class="sidebar-link">Self attention</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#pixelshuffle" class="sidebar-link">PixelShuffle</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#sequential-extensions" class="sidebar-link">Sequential extensions</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#concat" class="sidebar-link">Concat</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#ready-to-go-models" class="sidebar-link">Ready-to-go models</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#swish-and-mish" class="sidebar-link">Swish and Mish</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/layers.html#helper-functions-for-submodules" class="sidebar-link">Helper functions for submodules</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="layers"><a href="#layers" class="header-anchor">#</a> Layers</h1> <blockquote><p>Custom fastai layers and basic functions to grab them.</p></blockquote> <h2 id="basic-manipulations-and-resize"><a href="#basic-manipulations-and-resize" class="header-anchor">#</a> Basic manipulations and resize</h2> <h4 id="module" class="doc_header"><code>module</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L21" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>module</code>(<strong>*<code>flds</code></strong>, <strong>**<code>defaults</code></strong>)</p></blockquote> <p>Decorator to create an <code>nn.Module</code> using <code>f</code> as <code>forward</code> method</p> <h3 id="Identity" class="doc_header"><code>class</code> <code>Identity</code><a href="" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Identity</code>() :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Do nothing at all</p> <div class="language-python extra-class"><pre class="language-python"><code>test_eq<span class="token punctuation">(</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="Lambda" class="doc_header"><code>class</code> <code>Lambda</code><a href="" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Lambda</code>(<strong><code>func</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>An easy way to create a pytorch layer for a simple <code>func</code></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">_add2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> x<span class="token operator">+</span><span class="token number">2</span>
tst <span class="token operator">=</span> Lambda<span class="token punctuation">(</span>_add2<span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span>
tst2 <span class="token operator">=</span> pickle<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>tst<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span>
tst
</code></pre></div><div class="language- extra-class"><pre><code>Lambda(func=_add2)
</code></pre></div><h3 id="PartialLambda" class="doc_header"><code>class</code> <code>PartialLambda</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L57" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>PartialLambda</code>(<strong><code>func</code></strong>) :: <a href="/fastai/layers.html#Lambda"><code>Lambda</code></a></p></blockquote> <p>Layer that applies <code>partial(func, **kwargs)</code></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">test_func</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> a<span class="token operator">+</span>b
tst <span class="token operator">=</span> PartialLambda<span class="token punctuation">(</span>test_func<span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token operator">+</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="Flatten" class="doc_header"><code>class</code> <code>Flatten</code><a href="" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Flatten</code>(<strong><code>full</code></strong>=<em><code>False</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Flatten <code>x</code> to a single dimension, e.g. at end of a model. <code>full</code> for rank-1 tensor</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> Flatten<span class="token punctuation">(</span>full<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="View" class="doc_header"><code>class</code> <code>View</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L73" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>View</code>(<strong>*<code>size</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Reshape <code>x</code> to <code>size</code></p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> View<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="ResizeBatch" class="doc_header"><code>class</code> <code>ResizeBatch</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L79" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>ResizeBatch</code>(<strong>*<code>size</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Reshape <code>x</code> to <code>size</code>, keeping batch dim the same size</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ResizeBatch<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="Debugger" class="doc_header"><code>class</code> <code>Debugger</code><a href="" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Debugger</code>() :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>A module to debug inside a model.</p> <h4 id="sigmoid_range" class="doc_header"><code>sigmoid_range</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L92" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>sigmoid_range</code>(<strong><code>x</code></strong>, <strong><code>low</code></strong>, <strong><code>high</code></strong>)</p></blockquote> <p>Sigmoid function with range <code>(low, high)</code></p> <div class="language-python extra-class"><pre class="language-python"><code>test <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>sigmoid_range<span class="token punctuation">(</span>test<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> atol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> rtol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>sigmoid_range<span class="token punctuation">(</span>test<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> atol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> rtol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>sigmoid_range<span class="token punctuation">(</span>test<span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> atol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> rtol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="SigmoidRange" class="doc_header"><code>class</code> <code>SigmoidRange</code><a href="" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>SigmoidRange</code>(<strong><code>low</code></strong>, <strong><code>high</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Sigmoid module with range <code>(low, high)</code></p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> SigmoidRange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> atol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> rtol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="pooling-layers"><a href="#pooling-layers" class="header-anchor">#</a> Pooling layers</h2> <h3 id="AdaptiveConcatPool1d" class="doc_header"><code>class</code> <code>AdaptiveConcatPool1d</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L103" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>AdaptiveConcatPool1d</code>(<strong><code>size</code></strong>=<em><code>None</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Layer that concats <code>AdaptiveAvgPool1d</code> and <code>AdaptiveMaxPool1d</code></p> <h3 id="AdaptiveConcatPool2d" class="doc_header"><code>class</code> <code>AdaptiveConcatPool2d</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L112" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>AdaptiveConcatPool2d</code>(<strong><code>size</code></strong>=<em><code>None</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Layer that concats <code>AdaptiveAvgPool2d</code> and <code>AdaptiveMaxPool2d</code></p> <p>If the input is <code>bs x nf x h x h</code>, the output will be <code>bs x 2*nf x 1 x 1</code> if no size is passed or <code>bs x 2*nf x size x size</code></p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> AdaptiveConcatPool2d<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
max1 <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>    dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
maxp <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>max1<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> maxp<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> AdaptiveConcatPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="PoolType" class="doc_header"><code>class</code> <code>PoolType</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L121" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>PoolType</code>()</p></blockquote> <h4 id="adaptive_pool" class="doc_header"><code>adaptive_pool</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L124" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>adaptive_pool</code>(<strong><code>pool_type</code></strong>)</p></blockquote> <h3 id="PoolFlatten" class="doc_header"><code>class</code> <code>PoolFlatten</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L128" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>PoolFlatten</code>(<strong><code>pool_type</code></strong>=<em><code>'Avg'</code></em>) :: <code>Sequential</code></p></blockquote> <p>Combine <code>nn.AdaptiveAvgPool2d</code> and <a href="/fastai/layers.html#Flatten"><code>Flatten</code></a>.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> PoolFlatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="batchnorm-layers"><a href="#batchnorm-layers" class="header-anchor">#</a> BatchNorm layers</h2> <h4 id="BatchNorm" class="doc_header"><code>BatchNorm</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L146" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>BatchNorm</code>(<strong><code>nf</code></strong>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>norm_type</code></strong>=<em><code>&lt;NormType.Batch: 1&gt;</code></em>, <strong><code>eps</code></strong>=<em><code>1e-05</code></em>, <strong><code>momentum</code></strong>=<em><code>0.1</code></em>, <strong><code>affine</code></strong>=<em><code>True</code></em>, <strong><code>track_running_stats</code></strong>=<em><code>True</code></em>)</p></blockquote> <p>BatchNorm layer with <code>nf</code> features and <code>ndim</code> initialized depending on <code>norm_type</code>.</p> <h4 id="InstanceNorm" class="doc_header"><code>InstanceNorm</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L152" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>InstanceNorm</code>(<strong><code>nf</code></strong>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>norm_type</code></strong>=<em><code>&lt;NormType.Instance: 5&gt;</code></em>, <strong><code>affine</code></strong>=<em><code>True</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-05</code></em>, <strong><code>momentum</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>track_running_stats</code></strong>:<code>bool</code>=<em><code>False</code></em>)</p></blockquote> <p>InstanceNorm layer with <code>nf</code> features and <code>ndim</code> initialized depending on <code>norm_type</code>.</p> <p><code>kwargs</code> are passed to <code>nn.BatchNorm</code> and can be <code>eps</code>, <code>momentum</code>, <code>affine</code> and <code>track_running_stats</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> BatchNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> BatchNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span>NormType<span class="token punctuation">.</span>BatchZero<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> BatchNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">)</span>
tst <span class="token operator">=</span> BatchNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> InstanceNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> InstanceNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span>NormType<span class="token punctuation">.</span>InstanceZero<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> InstanceNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>InstanceNorm1d<span class="token punctuation">)</span>
tst <span class="token operator">=</span> InstanceNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tst<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">)</span>
</code></pre></div><p>If <code>affine</code> is false the weight should be <code>None</code></p> <div class="language-python extra-class"><pre class="language-python"><code>test_eq<span class="token punctuation">(</span>BatchNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>InstanceNorm<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="BatchNorm1dFlat" class="doc_header"><code>class</code> <code>BatchNorm1dFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L158" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>BatchNorm1dFlat</code>(<strong><code>num_features</code></strong>, <strong><code>eps</code></strong>=<em><code>1e-05</code></em>, <strong><code>momentum</code></strong>=<em><code>0.1</code></em>, <strong><code>affine</code></strong>=<em><code>True</code></em>, <strong><code>track_running_stats</code></strong>=<em><code>True</code></em>) :: <code>BatchNorm1d</code></p></blockquote> <p><code>nn.BatchNorm1d</code>, but first flattens leading dimensions</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> BatchNorm1dFlat<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_close<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>running_mean<span class="token punctuation">,</span> <span class="token number">0</span><span class="token operator">*</span><span class="token number">0.9</span> <span class="token operator">+</span> mean<span class="token operator">*</span><span class="token number">0.1</span><span class="token punctuation">)</span>
var <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token operator">-</span>mean<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_close<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>running_var<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span><span class="token number">0.9</span> <span class="token operator">+</span> var<span class="token operator">*</span><span class="token number">0.1</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
test_close<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token operator">-</span>mean<span class="token punctuation">)</span><span class="token operator">/</span>torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var<span class="token operator">+</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">*</span> tst<span class="token punctuation">.</span>weight <span class="token operator">+</span> tst<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="LinBnDrop" class="doc_header"><code>class</code> <code>LinBnDrop</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L167" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>LinBnDrop</code>(<strong><code>n_in</code></strong>, <strong><code>n_out</code></strong>, <strong><code>bn</code></strong>=<em><code>True</code></em>, <strong><code>p</code></strong>=<em><code>0.0</code></em>, <strong><code>act</code></strong>=<em><code>None</code></em>, <strong><code>lin_first</code></strong>=<em><code>False</code></em>) :: <code>Sequential</code></p></blockquote> <p>Module grouping <code>BatchNorm1d</code>, <code>Dropout</code> and <code>Linear</code> layers</p> <p>The <a href="/fastai/layers.html#BatchNorm"><code>BatchNorm</code></a> layer is skipped if <code>bn=False</code>, as is the dropout if <code>p=0.</code>. Optionally, you can add an activation for after the linear layer with <code>act</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> LinBnDrop<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span>

tst <span class="token operator">=</span> LinBnDrop<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span>

tst <span class="token operator">=</span> LinBnDrop<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> act<span class="token operator">=</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lin_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">)</span>

tst <span class="token operator">=</span> LinBnDrop<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span>
</code></pre></div><h2 id="inits"><a href="#inits" class="header-anchor">#</a> Inits</h2> <h4 id="sigmoid" class="doc_header"><code>sigmoid</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L178" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>sigmoid</code>(<strong><code>input</code></strong>, <strong><code>eps</code></strong>=<em><code>1e-07</code></em>)</p></blockquote> <p>Same as <code>torch.sigmoid</code>, plus clamping to `(eps,1-eps)</p> <h4 id="sigmoid_" class="doc_header"><code>sigmoid_</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L183" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>sigmoid_</code>(<strong><code>input</code></strong>, <strong><code>eps</code></strong>=<em><code>1e-07</code></em>)</p></blockquote> <p>Same as <code>torch.sigmoid_</code>, plus clamping to `(eps,1-eps)</p> <h4 id="vleaky_relu" class="doc_header"><code>vleaky_relu</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L191" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>vleaky_relu</code>(<strong><code>input</code></strong>, <strong><code>inplace</code></strong>=<em><code>True</code></em>)</p></blockquote> <p><code>F.leaky_relu</code> with 0.3 slope</p> <h4 id="init_default" class="doc_header"><code>init_default</code><a href="https://github.com/fastai/fastai/tree/master/fastai/torch_core.py#L683" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>init_default</code>(<strong><code>m</code></strong>, <strong><code>func</code></strong>=<em><code>kaiming_normal_</code></em>)</p></blockquote> <p>Initialize <code>m</code> weights with <code>func</code> and set <code>bias</code> to 0.</p> <h4 id="init_linear" class="doc_header"><code>init_linear</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L212" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>init_linear</code>(<strong><code>m</code></strong>, <strong><code>act_func</code></strong>=<em><code>None</code></em>, <strong><code>init</code></strong>=<em><code>'auto'</code></em>, <strong><code>bias_std</code></strong>=<em><code>0.01</code></em>)</p></blockquote> <h2 id="convolutions"><a href="#convolutions" class="header-anchor">#</a> Convolutions</h2> <h3 id="ConvLayer" class="doc_header"><code>class</code> <code>ConvLayer</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L232" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>ConvLayer</code>(<strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>bias</code></strong>=<em><code>None</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>norm_type</code></strong>=<em><code>&lt;NormType.Batch: 1&gt;</code></em>, <strong><code>bn_1st</code></strong>=<em><code>True</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>transpose</code></strong>=<em><code>False</code></em>, <strong><code>init</code></strong>=<em><code>'auto'</code></em>, <strong><code>xtra</code></strong>=<em><code>None</code></em>, <strong><code>bias_std</code></strong>=<em><code>0.01</code></em>, <strong><code>dilation</code></strong>:<code>Union</code>[<code>int</code>, <code>Tuple</code>[<code>int</code>, <code>int</code>]]=<em><code>1</code></em>, <strong><code>groups</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>) :: <code>Sequential</code></p></blockquote> <p>Create a sequence of convolutional (<code>ni</code> to <code>nf</code>), ReLU (if <code>use_activ</code>) and <code>norm_type</code> layers.</p> <p>The convolution uses <code>ks</code> (kernel size) <code>stride</code>, <code>padding</code> and <code>bias</code>. <code>padding</code> will default to the appropriate value (<code>(ks-1)//2</code> if it's not a transposed conv) and <code>bias</code> will default to <code>True</code> the <code>norm_type</code> is <code>Spectral</code> or <code>Weight</code>, <code>False</code> if it's <code>Batch</code> or <code>BatchZero</code>. Note that if you don't want any normalization, you should pass <code>norm_type=None</code>.</p> <p>This defines a conv layer with <code>ndim</code> (1,2 or 3) that will be a ConvTranspose if <code>transpose=True</code>. <code>act_cls</code> is the class of the activation function to use (instantiated inside). Pass <code>act=None</code> if you don't want an activation function. If you quickly want to change your default activation, you can change the value of <a href="/fastai/layers.html#defaults.activation"><code>defaults.activation</code></a>.</p> <p><code>init</code> is used to initialize the weights (the bias are initialized to 0) and <code>xtra</code> is an optional layer to add at the end.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>padding<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token comment">#.cuda()</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">assert</span> mods<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token boolean">None</span>
<span class="token comment">#But can be overridden with `bias=True`</span>
tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> first<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
<span class="token comment">#For no norm, or spectral/weight, bias is True by default</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> NormType<span class="token punctuation">.</span>Spectral<span class="token punctuation">,</span> NormType<span class="token punctuation">.</span>Weight<span class="token punctuation">]</span><span class="token punctuation">:</span>
    tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span>t<span class="token punctuation">)</span>
    <span class="token keyword">assert</span> first<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">)</span>
tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> transpose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ConvTranspose1d<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> act_cls<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> ndim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> act_cls<span class="token operator">=</span>partial<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">,</span> negative_slope<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>mods<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># def linear(in_features, out_features, bias=True, act_cls=None, init='auto'):</span>
<span class="token comment">#     &quot;Linear layer followed by optional activation, with optional auto-init&quot;</span>
<span class="token comment">#     res = nn.Linear(in_features, out_features, bias=bias)</span>
<span class="token comment">#     if act_cls: act_cls = act_cls()</span>
<span class="token comment">#     init_linear(res, act_cls, init=init)</span>
<span class="token comment">#     if act_cls: res = nn.Sequential(res, act_cls)</span>
<span class="token comment">#     return res</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># @delegates(ConvLayer)</span>
<span class="token comment"># def conv1d(ni, nf, ks, stride=1, ndim=1, norm_type=None, **kwargs):</span>
<span class="token comment">#     &quot;Convolutional layer followed by optional activation, with optional auto-init&quot;</span>
<span class="token comment">#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># @delegates(ConvLayer)</span>
<span class="token comment"># def conv2d(ni, nf, ks, stride=1, ndim=2, norm_type=None, **kwargs):</span>
<span class="token comment">#     &quot;Convolutional layer followed by optional activation, with optional auto-init&quot;</span>
<span class="token comment">#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># @delegates(ConvLayer)</span>
<span class="token comment"># def conv3d(ni, nf, ks, stride=1, ndim=3, norm_type=None, **kwargs):</span>
<span class="token comment">#     &quot;Convolutional layer followed by optional activation, with optional auto-init&quot;</span>
<span class="token comment">#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)</span>
</code></pre></div><h4 id="AdaptiveAvgPool" class="doc_header"><code>AdaptiveAvgPool</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L258" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>AdaptiveAvgPool</code>(<strong><code>sz</code></strong>=<em><code>1</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>)</p></blockquote> <p>nn.AdaptiveAvgPool layer for <code>ndim</code></p> <h4 id="MaxPool" class="doc_header"><code>MaxPool</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L264" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>MaxPool</code>(<strong><code>ks</code></strong>=<em><code>2</code></em>, <strong><code>stride</code></strong>=<em><code>None</code></em>, <strong><code>padding</code></strong>=<em><code>0</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>ceil_mode</code></strong>=<em><code>False</code></em>)</p></blockquote> <p>nn.MaxPool layer for <code>ndim</code></p> <h4 id="AvgPool" class="doc_header"><code>AvgPool</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L270" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>AvgPool</code>(<strong><code>ks</code></strong>=<em><code>2</code></em>, <strong><code>stride</code></strong>=<em><code>None</code></em>, <strong><code>padding</code></strong>=<em><code>0</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>ceil_mode</code></strong>=<em><code>False</code></em>)</p></blockquote> <p>nn.AvgPool layer for <code>ndim</code></p> <h2 id="fastai-loss-functions"><a href="#fastai-loss-functions" class="header-anchor">#</a> fastai loss functions</h2> <p>The following class if the base class to warp a loss function it provides several added functionality:</p> <ul><li>it flattens the tensors before trying to take the losses since it's more convenient (with a potential tranpose to put <code>axis</code> at the end)</li> <li>it has a potential <code>activation</code> method that tells the library if there is an activation fused in the loss (useful for inference and methods such as <a href="/fastai/learner.html#Learner.get_preds"><code>Learner.get_preds</code></a> or <a href="/fastai/learner.html#Learner.predict"><code>Learner.predict</code></a>)</li> <li>it has a potential <code>decodes</code> method that is used on predictions in inference (for instance, an argmax in classification)</li></ul> <div class="language-python extra-class"><pre class="language-python"><code>F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>tensor([[0.4444, 1.1849, 1.1411, 2.2376, 0.4800],
        [3.0970, 0.2376, 0.2159, 2.0667, 0.5246],
        [0.7885, 0.7743, 0.5355, 0.6340, 1.5417],
        [0.5340, 0.4066, 0.9115, 0.5817, 0.2920]])
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>funcs_kwargs
</code></pre></div><div class="language- extra-class"><pre><code>&lt;function fastcore.foundation.funcs_kwargs(cls)&gt;
</code></pre></div><h3 id="BaseLoss" class="doc_header"><code>class</code> <code>BaseLoss</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L277" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>BaseLoss</code>(<strong><code>loss_cls</code></strong>, <strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>flatten</code></strong>=<em><code>True</code></em>, <strong><code>floatify</code></strong>=<em><code>False</code></em>, <strong><code>is_2d</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p></blockquote> <p>Same as <code>loss_cls</code>, but flattens input and target.</p> <p>The <code>args</code> and <code>kwargs</code> will be passed to <code>loss_cls</code> during the initialization to instantiate a loss function. <code>axis</code> is put at the end for losses like softmax that are often performed on the last axis. If <code>floatify=True</code> the targs will be converted to float (useful for losses that only accept float targets like <code>BCEWithLogitsLoss</code>) and <code>is_2d</code> determines if we flatten while keeping the first dimension (batch size) or completely flatten the input. We want the first for losses like Cross Entropy, and the second for pretty much anything else.</p> <h3 id="CrossEntropyLossFlat" class="doc_header"><code>class</code> <code>CrossEntropyLossFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L302" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>CrossEntropyLossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>weight</code></strong>=<em><code>None</code></em>, <strong><code>ignore_index</code></strong>=<em><code>-100</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>flatten</code></strong>=<em><code>True</code></em>, <strong><code>floatify</code></strong>=<em><code>False</code></em>, <strong><code>is_2d</code></strong>=<em><code>True</code></em>) :: <a href="/fastai/layers.html#BaseLoss"><code>BaseLoss</code></a></p></blockquote> <p>Same as <code>nn.CrossEntropyLoss</code>, but flattens input and target.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#nn.CrossEntropy would fail with those two tensors, but not our flattened version.</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#Associated activation is softmax</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#This loss function has a decodes which is argmax</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>decodes<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> CrossEntropyLossFlat<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>decodes<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="BCEWithLogitsLossFlat" class="doc_header"><code>class</code> <code>BCEWithLogitsLossFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L313" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>BCEWithLogitsLossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>floatify</code></strong>=<em><code>True</code></em>, <strong><code>thresh</code></strong>=<em><code>0.5</code></em>, <strong><code>weight</code></strong>=<em><code>None</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>pos_weight</code></strong>=<em><code>None</code></em>, <strong><code>flatten</code></strong>=<em><code>True</code></em>, <strong><code>is_2d</code></strong>=<em><code>True</code></em>) :: <a href="/fastai/layers.html#BaseLoss"><code>BaseLoss</code></a></p></blockquote> <p>Same as <code>nn.CrossEntropyLoss</code>, but flattens input and target.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> BCEWithLogitsLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
<span class="token comment">#nn.BCEWithLogitsLoss would fail with those two tensors, but not our flattened version.</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#nn.BCEWithLogitsLoss would fail with int targets but not our flattened version.</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#Associated activation is sigmoid</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="BCELossFlat" class="doc_header"><code>BCELossFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L324" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>BCELossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>floatify</code></strong>=<em><code>True</code></em>, <strong><code>weight</code></strong>=<em><code>None</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>)</p></blockquote> <p>Same as <code>nn.BCELoss</code>, but flattens input and target.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> BCELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="MSELossFlat" class="doc_header"><code>MSELossFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L331" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>MSELossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>floatify</code></strong>=<em><code>True</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>)</p></blockquote> <p>Same as <code>nn.MSELoss</code>, but flattens input and target.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> tst<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="L1LossFlat" class="doc_header"><code>L1LossFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L338" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>L1LossFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>floatify</code></strong>=<em><code>True</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>)</p></blockquote> <p>Same as <code>nn.L1Loss</code>, but flattens input and target.</p> <h3 id="LabelSmoothingCrossEntropy" class="doc_header"><code>class</code> <code>LabelSmoothingCrossEntropy</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L346" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>LabelSmoothingCrossEntropy</code>(<strong><code>eps</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p> <p>On top of the formula we define:</p> <ul><li>a <code>reduction</code> attribute, that will be used when we call <a href="/fastai/learner.html#Learner.get_preds"><code>Learner.get_preds</code></a></li> <li>an <code>activation</code> function that represents the activation fused in the loss (since we use cross entropy behind the scenes). It will be applied to the output of the model when calling <a href="/fastai/learner.html#Learner.get_preds"><code>Learner.get_preds</code></a> or <a href="/fastai/learner.html#Learner.predict"><code>Learner.predict</code></a></li> <li>a <code>decodes</code> function that converts the output of the model to a format similar to the target (here indices). This is used in <a href="/fastai/learner.html#Learner.predict"><code>Learner.predict</code></a> and <a href="/fastai/learner.html#Learner.show_results"><code>Learner.show_results</code></a> to decode the predictions</li></ul> <h3 id="LabelSmoothingCrossEntropyFlat" class="doc_header"><code>class</code> <code>LabelSmoothingCrossEntropyFlat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L365" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>LabelSmoothingCrossEntropyFlat</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>eps</code></strong>=<em><code>0.1</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>flatten</code></strong>=<em><code>True</code></em>, <strong><code>floatify</code></strong>=<em><code>False</code></em>, <strong><code>is_2d</code></strong>=<em><code>True</code></em>) :: <a href="/fastai/layers.html#BaseLoss"><code>BaseLoss</code></a></p></blockquote> <p>Same as <a href="/fastai/layers.html#LabelSmoothingCrossEntropy"><code>LabelSmoothingCrossEntropy</code></a>, but flattens input and target.</p> <h2 id="embeddings"><a href="#embeddings" class="header-anchor">#</a> Embeddings</h2> <h4 id="trunc_normal_" class="doc_header"><code>trunc_normal_</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L374" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>trunc_normal_</code>(<strong><code>x</code></strong>, <strong><code>mean</code></strong>=<em><code>0.0</code></em>, <strong><code>std</code></strong>=<em><code>1.0</code></em>)</p></blockquote> <p>Truncated normal initialization (approximation)</p> <h3 id="Embedding" class="doc_header"><code>class</code> <code>Embedding</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L380" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Embedding</code>(<strong><code>ni</code></strong>, <strong><code>nf</code></strong>) :: <a href="/fastai/layers.html#Embedding"><code>Embedding</code></a></p></blockquote> <p>Embedding layer with truncated normal initialization</p> <p>Truncated normal initialization bounds the distribution to avoid large value. For a given standard deviation <code>std</code>, the bounds are roughly <code>-std</code>, <code>std</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> tst<span class="token punctuation">.</span>weight<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token operator">-</span><span class="token number">0.02</span>
<span class="token keyword">assert</span> tst<span class="token punctuation">.</span>weight<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0.02</span>
test_close<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
test_close<span class="token punctuation">(</span>tst<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="self-attention"><a href="#self-attention" class="header-anchor">#</a> Self attention</h2> <h3 id="SelfAttention" class="doc_header"><code>class</code> <code>SelfAttention</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L387" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>SelfAttention</code>(<strong><code>n_channels</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Self attention layer for <code>n_channels</code>.</p> <p>Self-attention layer as introduced in <a href="https://arxiv.org/abs/1805.08318" target="_blank" rel="noopener noreferrer">Self-Attention Generative Adversarial Networks<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p>Initially, no change is done to the input. This is controlled by a trainable parameter named <code>gamma</code> as we return <code>x + gamma * out</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> SelfAttention<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
</code></pre></div><p>Then during training <code>gamma</code> will probably change since it's a trainable parameter. Let's see what's happening when it gets a nonzero value.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst<span class="token punctuation">.</span>gamma<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tst<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>The attention mechanism requires three matrix multiplications (here represented by 1x1 convs). The multiplications are done on the channel level (the second dimension in our tensor) and we flatten the feature map (which is 8x8 here). As in the paper, we note <code>f</code>, <code>g</code> and <code>h</code> the results of those multiplications.</p> <div class="language-python extra-class"><pre class="language-python"><code>q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v <span class="token operator">=</span> tst<span class="token punctuation">.</span>query<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span>tst<span class="token punctuation">.</span>key<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span>tst<span class="token punctuation">.</span>value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data
test_eq<span class="token punctuation">(</span><span class="token punctuation">[</span>q<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> k<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> v<span class="token punctuation">.</span>shape<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
f<span class="token punctuation">,</span>g<span class="token punctuation">,</span>h <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> m<span class="token punctuation">:</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> @ m<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token punctuation">[</span>f<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> g<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> h<span class="token punctuation">.</span>shape<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>The key part of the attention layer is to compute attention weights for each of our location in the feature map (here 8x8 = 64). Those are positive numbers that sum to 1 and tell the model to pay attention to this or that part of the picture. We make the product of <code>f</code> and the transpose of <code>g</code> (to get something of size bs by 64 by 64) then apply a softmax on the first dimension (to get the positive numbers that sum up to 1). The result can then be multiplied with <code>h</code> transposed to get an output of size bs by channels by 64, which we can then be viewed as an output the same size as the original input.</p> <p>The final result is then <code>x + gamma * out</code> as we saw before.</p> <div class="language-python extra-class"><pre class="language-python"><code>beta <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>f<span class="token punctuation">,</span> g<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>beta<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
out <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>h<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> beta<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_close<span class="token punctuation">(</span>y<span class="token punctuation">,</span> x <span class="token operator">+</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="PooledSelfAttention2d" class="doc_header"><code>class</code> <code>PooledSelfAttention2d</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L406" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>PooledSelfAttention2d</code>(<strong><code>n_channels</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Pooled self attention layer for 2d.</p> <p>Self-attention layer used in the <a href="https://arxiv.org/abs/1809.11096" target="_blank" rel="noopener noreferrer">Big GAN paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p>It uses the same attention as in <a href="/fastai/layers.html#SelfAttention"><code>SelfAttention</code></a> but adds a max pooling of stride 2 before computing the matrices <code>g</code> and <code>h</code>: the attention is ported on one of the 2x2 max-pooled window, not the whole feature map. There is also a final matrix product added at the end to the output, before retuning <code>gamma * out + x</code>.</p> <h3 id="SimpleSelfAttention" class="doc_header"><code>class</code> <code>SimpleSelfAttention</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L435" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>SimpleSelfAttention</code>(<strong><code>n_in</code></strong>:<code>int</code>, <strong><code>ks</code></strong>=<em><code>1</code></em>, <strong><code>sym</code></strong>=<em><code>False</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p> <h2 id="pixelshuffle"><a href="#pixelshuffle" class="header-anchor">#</a> PixelShuffle</h2> <p>PixelShuffle introduced in <a href="https://arxiv.org/pdf/1609.05158.pdf" target="_blank" rel="noopener noreferrer">this article<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> to avoid checkerboard artifacts when upsampling images. If we want an output with <code>ch_out</code> filters, we use a convolution with <code>ch_out * (r**2)</code> filters, where <code>r</code> is the upsampling factor. Then we reorganize those filters like in the picture below:</p> <p>{% include image.html alt=&quot;Pixelshuffle&quot; style=&quot;width: 100%; height: auto;&quot; file=&quot;/images/pixelshuffle.png&quot; %}</p> <h4 id="icnr_init" class="doc_header"><code>icnr_init</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L457" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>icnr_init</code>(<strong><code>x</code></strong>, <strong><code>scale</code></strong>=<em><code>2</code></em>, <strong><code>init</code></strong>=<em><code>kaiming_normal_</code></em>)</p></blockquote> <p>ICNR init of <code>x</code>, with <code>scale</code> and <code>init</code> function</p> <p>ICNR init was introduced in <a href="https://arxiv.org/abs/1707.02937" target="_blank" rel="noopener noreferrer">this article<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>. It suggests to initialize the convolution that will be used in PixelShuffle so that each of the <code>r**2</code> channels get the same weight (so that in the picture above, the 9 colors in a 3 by 3 window are initially the same).
{% include note.html content='This is done on the first dimension because PyTorch stores the weights of a convolutional layer in this format: <code>ch_out x ch_in x ks x ks</code>. ' %}</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
tst <span class="token operator">=</span> icnr_init<span class="token punctuation">(</span>tst<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>tst<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>tst<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    test_eq<span class="token punctuation">(</span>tst<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>tst<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="PixelShuffle_ICNR" class="doc_header"><code>class</code> <code>PixelShuffle_ICNR</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L467" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>PixelShuffle_ICNR</code>(<strong><code>ni</code></strong>, <strong><code>nf</code></strong>=<em><code>None</code></em>, <strong><code>scale</code></strong>=<em><code>2</code></em>, <strong><code>blur</code></strong>=<em><code>False</code></em>, <strong><code>norm_type</code></strong>=<em><code>&lt;NormType.Weight: 3&gt;</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>) :: <code>Sequential</code></p></blockquote> <p>Upsample by <code>scale</code> from <code>ni</code> filters to <code>nf</code> (default <code>ni</code>), using <code>nn.PixelShuffle</code>.</p> <p>The convolutional layer is initialized with <a href="/fastai/layers.html#icnr_init"><code>icnr_init</code></a> and passed <code>act_cls</code> and <code>norm_type</code> (the default of weight normalization seemed to be what's best for super-resolution problems, in our experiments).</p> <p>The <code>blur</code> option comes from <a href="https://arxiv.org/abs/1806.02658" target="_blank" rel="noopener noreferrer">Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> where the authors add a little bit of blur to completely get rid of checkerboard artifacts.</p> <div class="language-python extra-class"><pre class="language-python"><code>psfl <span class="token operator">=</span> PixelShuffle_ICNR<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment">#Deactivate weight norm as it changes the weight</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> psfl<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#ICNR init makes every 2x2 window (stride 2) have the same elements</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_eq<span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
        test_eq<span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i  <span class="token punctuation">,</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        test_eq<span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="sequential-extensions"><a href="#sequential-extensions" class="header-anchor">#</a> Sequential extensions</h2> <h4 id="sequential" class="doc_header"><code>sequential</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L479" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>sequential</code>(<strong>*<code>args</code></strong>)</p></blockquote> <p>Create an <code>nn.Sequential</code>, wrapping items with <a href="/fastai/layers.html#Lambda"><code>Lambda</code></a> if needed</p> <h3 id="SequentialEx" class="doc_header"><code>class</code> <code>SequentialEx</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L488" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>SequentialEx</code>(<strong>*<code>layers</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Like <code>nn.Sequential</code>, but with ModuleList semantics, and can access module input</p> <p>This is useful to write layers that require to remember the input (like a resnet block) in a sequential way.</p> <h3 id="MergeLayer" class="doc_header"><code>class</code> <code>MergeLayer</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L508" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>MergeLayer</code>(<strong><code>dense</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Merge a shortcut with the result of the module by adding them or concatenating them if <code>dense=True</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>res_block <span class="token operator">=</span> SequentialEx<span class="token punctuation">(</span>ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ConvLayer<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
res_block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>MergeLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># just to test append - normally it would be in init params</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> res_block<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>y<span class="token punctuation">,</span> x <span class="token operator">+</span> res_block<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">(</span>res_block<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="concat"><a href="#concat" class="header-anchor">#</a> Concat</h2> <p>Equivalent to keras.layers.Concatenate, it will concat the outputs of a ModuleList over a given dimension (default the filter dimension)</p> <h3 id="Cat" class="doc_header"><code>class</code> <code>Cat</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L514" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Cat</code>(<strong><code>layers</code></strong>, <strong><code>dim</code></strong>=<em><code>1</code></em>) :: <code>ModuleList</code></p></blockquote> <p>Concatenate layers outputs over a given dim</p> <div class="language-python extra-class"><pre class="language-python"><code>layers <span class="token operator">=</span> <span class="token punctuation">[</span>ConvLayer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ConvLayer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ConvLayer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span> 
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span> 
cat <span class="token operator">=</span> Cat<span class="token punctuation">(</span>layers<span class="token punctuation">)</span> 
test_eq<span class="token punctuation">(</span>cat<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
test_eq<span class="token punctuation">(</span>cat<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>l<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> layers<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="ready-to-go-models"><a href="#ready-to-go-models" class="header-anchor">#</a> Ready-to-go models</h2> <h3 id="SimpleCNN" class="doc_header"><code>class</code> <code>SimpleCNN</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L522" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>SimpleCNN</code>(<strong><code>filters</code></strong>, <strong><code>kernel_szs</code></strong>=<em><code>None</code></em>, <strong><code>strides</code></strong>=<em><code>None</code></em>, <strong><code>bn</code></strong>=<em><code>True</code></em>) :: <code>Sequential</code></p></blockquote> <p>Create a simple CNN with <code>filters</code>.</p> <p>The model is a succession of convolutional layers from <code>(filters[0],filters[1])</code> to <code>(filters[n-2],filters[n-1])</code> (if <code>n</code> is the length of the <code>filters</code> list) followed by a <a href="/fastai/layers.html#PoolFlatten"><code>PoolFlatten</code></a>. <code>kernel_szs</code> and <code>strides</code> defaults to a list of 3s and a list of 2s. If <code>bn=True</code> the convolutional layers are successions of conv-relu-batchnorm, otherwise conv-relu.</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> SimpleCNN<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>mods<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>m<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> m<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>out_channels<span class="token punctuation">]</span> <span class="token keyword">for</span> m <span class="token keyword">in</span> mods<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>Test kernel sizes</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> SimpleCNN<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_szs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token punctuation">[</span>m<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>kernel_size <span class="token keyword">for</span> m <span class="token keyword">in</span> mods<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>Test strides</p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> SimpleCNN<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mods <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tst<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token punctuation">[</span>m<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>stride <span class="token keyword">for</span> m <span class="token keyword">in</span> mods<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="ProdLayer" class="doc_header"><code>class</code> <code>ProdLayer</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L534" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>ProdLayer</code>() :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Merge a shortcut with the result of the module by multiplying them.</p> <h4 id="SEModule" class="doc_header"><code>SEModule</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L542" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>SEModule</code>(<strong><code>ch</code></strong>, <strong><code>reduction</code></strong>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>)</p></blockquote> <h3 id="ResBlock" class="doc_header"><code>class</code> <code>ResBlock</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L550" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>ResBlock</code>(<strong><code>expansion</code></strong>, <strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>reduction</code></strong>=<em><code>None</code></em>, <strong><code>nh1</code></strong>=<em><code>None</code></em>, <strong><code>nh2</code></strong>=<em><code>None</code></em>, <strong><code>dw</code></strong>=<em><code>False</code></em>, <strong><code>g2</code></strong>=<em><code>1</code></em>, <strong><code>sa</code></strong>=<em><code>False</code></em>, <strong><code>sym</code></strong>=<em><code>False</code></em>, <strong><code>norm_type</code></strong>=<em><code>&lt;NormType.Batch: 1&gt;</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>pool</code></strong>=<em><code>AvgPool</code></em>, <strong><code>pool_first</code></strong>=<em><code>True</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>bias</code></strong>=<em><code>None</code></em>, <strong><code>bn_1st</code></strong>=<em><code>True</code></em>, <strong><code>transpose</code></strong>=<em><code>False</code></em>, <strong><code>init</code></strong>=<em><code>'auto'</code></em>, <strong><code>xtra</code></strong>=<em><code>None</code></em>, <strong><code>bias_std</code></strong>=<em><code>0.01</code></em>, <strong><code>dilation</code></strong>:<code>Union</code>[<code>int</code>, <code>Tuple</code>[<code>int</code>, <code>int</code>]]=<em><code>1</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Resnet block from <code>ni</code> to <code>nh</code> with <code>stride</code></p> <p>This is a resnet block (normal or bottleneck depending on <code>expansion</code>, 1 for the normal block and 4 for the traditional bottleneck) that implements the tweaks from <a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noopener noreferrer">Bag of Tricks for Image Classification with Convolutional Neural Networks<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>. In particular, the last batchnorm layer (if that is the selected <code>norm_type</code>) is initialized with a weight (or gamma) of zero to facilitate the flow from the beginning to the end of the network. It also implements optional <a href="https://arxiv.org/abs/1709.01507" target="_blank" rel="noopener noreferrer">Squeeze and Excitation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and grouped convs for <a href="https://arxiv.org/abs/1611.05431" target="_blank" rel="noopener noreferrer">ResNeXT<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and similar models (use <code>dw=True</code> for depthwise convs).</p> <p>The <code>kwargs</code> are passed to <a href="/fastai/layers.html#ConvLayer"><code>ConvLayer</code></a> along with <code>norm_type</code>.</p> <h4 id="SEBlock" class="doc_header"><code>SEBlock</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L581" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>SEBlock</code>(<strong><code>expansion</code></strong>, <strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>reduction</code></strong>=<em><code>16</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong>**<code>kwargs</code></strong>)</p></blockquote> <h4 id="SEResNeXtBlock" class="doc_header"><code>SEResNeXtBlock</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L585" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>SEResNeXtBlock</code>(<strong><code>expansion</code></strong>, <strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>groups</code></strong>=<em><code>32</code></em>, <strong><code>reduction</code></strong>=<em><code>16</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>base_width</code></strong>=<em><code>4</code></em>, <strong>**<code>kwargs</code></strong>)</p></blockquote> <h4 id="SeparableBlock" class="doc_header"><code>SeparableBlock</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L590" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>SeparableBlock</code>(<strong><code>expansion</code></strong>, <strong><code>ni</code></strong>, <strong><code>nf</code></strong>, <strong><code>reduction</code></strong>=<em><code>16</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>base_width</code></strong>=<em><code>4</code></em>, <strong>**<code>kwargs</code></strong>)</p></blockquote> <h2 id="swish-and-mish"><a href="#swish-and-mish" class="header-anchor">#</a> Swish and Mish</h2> <h4 id="swish" class="doc_header"><code>swish</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L616" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>swish</code>(<strong><code>x</code></strong>, <strong><code>inplace</code></strong>=<em><code>False</code></em>)</p></blockquote> <h3 id="Swish" class="doc_header"><code>class</code> <code>Swish</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L619" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Swish</code>() :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p> <h3 id="MishJitAutoFn" class="doc_header"><code>class</code> <code>MishJitAutoFn</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L632" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>MishJitAutoFn</code>() :: <code>Function</code></p></blockquote> <p>Records operation history and defines formulas for differentiating ops.</p> <p>See the Note on extending the autograd engine for more details on how to use
this class: https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd</p> <p>Every operation performed on :class:<code>Tensor</code> s creates a new function
object, that performs the computation, and records that it happened.
The history is retained in the form of a DAG of functions, with edges
denoting data dependencies (<code>input &lt;- output</code>). Then, when backward is
called, the graph is processed in the topological ordering, by calling
:func:<code>backward</code> methods of each :class:<code>Function</code> object, and passing
returned gradients on to next :class:<code>Function</code> s.</p> <p>Normally, the only way users interact with functions is by creating
subclasses and defining new operations. This is a recommended way of
extending torch.autograd.</p> <p>Examples::</p> <div class="language- extra-class"><pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; #Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)
</code></pre></div><h4 id="mish" class="doc_header"><code>mish</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L644" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>mish</code>(<strong><code>x</code></strong>)</p></blockquote> <h3 id="Mish" class="doc_header"><code>class</code> <code>Mish</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L647" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>Mish</code>() :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p> <h2 id="helper-functions-for-submodules"><a href="#helper-functions-for-submodules" class="header-anchor">#</a> Helper functions for submodules</h2> <p>It's easy to get the list of all parameters of a given model. For when you want all submodules (like linear/conv layers) without forgetting lone parameters, the following class wraps those in fake modules.</p> <h3 id="ParameterModule" class="doc_header"><code>class</code> <code>ParameterModule</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L654" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>ParameterModule</code>(<strong><code>p</code></strong>) :: <a href="/fastai/torch_core.html#Module"><code>Module</code></a></p></blockquote> <p>Register a lone parameter <code>p</code> in a module.</p> <h4 id="children_and_parameters" class="doc_header"><code>children_and_parameters</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L660" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>children_and_parameters</code>(<strong><code>m</code></strong>)</p></blockquote> <p>Return the children of <code>m</code> and its direct parameters not registered in modules.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TstModule</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>a<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lin <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>

tst <span class="token operator">=</span> TstModule<span class="token punctuation">(</span><span class="token punctuation">)</span>
children <span class="token operator">=</span> children_and_parameters<span class="token punctuation">(</span>tst<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>children<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tst<span class="token punctuation">.</span>lin<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>children<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ParameterModule<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>children<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>val<span class="token punctuation">,</span> tst<span class="token punctuation">.</span>a<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">pass</span>
<span class="token keyword">assert</span> <span class="token keyword">not</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>has_children
<span class="token keyword">assert</span> TstModule<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>has_children
</code></pre></div><h4 id="flatten_model" class="doc_header"><code>flatten_model</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L677" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>flatten_model</code>(<strong><code>m</code></strong>)</p></blockquote> <p>Return the list of all submodules and parameters of <code>m</code></p> <div class="language-python extra-class"><pre class="language-python"><code>tst <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>TstModule<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> TstModule<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
children <span class="token operator">=</span> flatten_model<span class="token punctuation">(</span>tst<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>children<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ParameterModule<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>children<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ParameterModule<span class="token punctuation">)</span>
</code></pre></div><h3 id="NoneReduce" class="doc_header"><code>class</code> <code>NoneReduce</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L682" class="source_link" style="float:right;">[source]</a></h3> <blockquote><p><code>NoneReduce</code>(<strong><code>loss_func</code></strong>)</p></blockquote> <p>A context manager to evaluate <code>loss_func</code> with none reduce.</p> <div class="language-python extra-class"><pre class="language-python"><code>x<span class="token punctuation">,</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> NoneReduce<span class="token punctuation">(</span>loss_fn<span class="token punctuation">)</span> <span class="token keyword">as</span> loss_func<span class="token punctuation">:</span>
    loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>loss_fn<span class="token punctuation">.</span>reduction<span class="token punctuation">,</span> <span class="token string">'mean'</span><span class="token punctuation">)</span>

loss_fn <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss
<span class="token keyword">with</span> NoneReduce<span class="token punctuation">(</span>loss_fn<span class="token punctuation">)</span> <span class="token keyword">as</span> loss_func<span class="token punctuation">:</span>
    loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>loss_fn<span class="token punctuation">,</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">)</span>
</code></pre></div><h4 id="in_channels" class="doc_header"><code>in_channels</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L697" class="source_link" style="float:right;">[source]</a></h4> <blockquote><p><code>in_channels</code>(<strong><code>m</code></strong>)</p></blockquote> <p>Return the shape of the first weight layer in <code>m</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>test_eq<span class="token punctuation">(</span>in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>BatchNorm<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>InstanceNorm<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
test_eq<span class="token punctuation">(</span>in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>InstanceNorm<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
test_fail<span class="token punctuation">(</span><span class="token keyword">lambda</span> <span class="token punctuation">:</span> in_channels<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/fastai/assets/js/app.e4c088e4.js" defer></script><script src="/fastai/assets/js/2.f1c4f916.js" defer></script><script src="/fastai/assets/js/29.7b21b9fd.js" defer></script>
  </body>
</html>
