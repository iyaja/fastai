(window.webpackJsonp=window.webpackJsonp||[]).push([[51],{397:function(t,s,a){"use strict";a.r(s);var n=a(42),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"interpretation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#interpretation"}},[t._v("#")]),t._v(" Interpretation")]),t._v(" "),a("blockquote",[a("p",[t._v("Classes to build objects to better interpret predictions of a model")])]),t._v(" "),a("h2",{staticClass:"doc_header",attrs:{id:"Interpretation"}},[a("code",[t._v("class")]),t._v(" "),a("code",[t._v("Interpretation")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/interpret.py#L20"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("Interpretation")]),t._v("("),a("strong",[a("code",[t._v("dl")])]),t._v(", "),a("strong",[a("code",[t._v("inputs")])]),t._v(", "),a("strong",[a("code",[t._v("preds")])]),t._v(", "),a("strong",[a("code",[t._v("targs")])]),t._v(", "),a("strong",[a("code",[t._v("decoded")])]),t._v(", "),a("strong",[a("code",[t._v("losses")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Interpretation base class, can be inherited for task specific Interpretation classes")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("learn "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" synth_learner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ninterp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Interpretation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_learner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dls"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid_ds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensors\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("interp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("interp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("targs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nout "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("interp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("interp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{staticClass:"doc_header",attrs:{id:"ClassificationInterpretation"}},[a("code",[t._v("class")]),t._v(" "),a("code",[t._v("ClassificationInterpretation")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/interpret.py#L51"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("ClassificationInterpretation")]),t._v("("),a("strong",[a("code",[t._v("dl")])]),t._v(", "),a("strong",[a("code",[t._v("inputs")])]),t._v(", "),a("strong",[a("code",[t._v("preds")])]),t._v(", "),a("strong",[a("code",[t._v("targs")])]),t._v(", "),a("strong",[a("code",[t._v("decoded")])]),t._v(", "),a("strong",[a("code",[t._v("losses")])]),t._v(") :: "),a("RouterLink",{attrs:{to:"/interpret.html#Interpretation"}},[a("code",[t._v("Interpretation")])])],1)]),t._v(" "),a("p",[t._v("Interpretation methods for classification models.")])])}),[],!1,null,null,null);s.default=e.exports}}]);