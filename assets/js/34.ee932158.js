(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{418:function(t,a,s){"use strict";s.r(a);var n=s(42),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"tutorial-migrating-from-ignite"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tutorial-migrating-from-ignite"}},[t._v("#")]),t._v(" Tutorial - Migrating from Ignite")]),t._v(" "),s("blockquote",[s("p",[t._v("Incrementally adding fastai goodness to your Ignite training")])]),t._v(" "),s("p",[t._v("We're going to use the MNIST training code from Ignite's examples directory (as at August 2020), converted to a module.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" migrating_ignite "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("all")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n")])])]),s("p",[t._v("To use it in fastai, we first pull the DataLoaders from the module into a "),s("RouterLink",{attrs:{to:"/data.core.html#DataLoaders"}},[s("code",[t._v("DataLoaders")])]),t._v(" object:")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DataLoaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("get_data_loaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("We can now create a "),s("RouterLink",{attrs:{to:"/learner.html#Learner"}},[s("code",[t._v("Learner")])]),t._v(" and fit:")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("opt_func "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" partial"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("SGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Learner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Net"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NLLLoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" opt_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt_func"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metrics"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("accuracy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_one_cycle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("table",{staticClass:"dataframe",attrs:{border:"1"}},[s("thead",[s("tr",{staticStyle:{"text-align":"left"}},[s("th",[t._v("epoch")]),t._v(" "),s("th",[t._v("train_loss")]),t._v(" "),s("th",[t._v("valid_loss")]),t._v(" "),s("th",[t._v("accuracy")]),t._v(" "),s("th",[t._v("time")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("0")]),t._v(" "),s("td",[t._v("0.999266")]),t._v(" "),s("td",[t._v("0.597913")]),t._v(" "),s("td",[t._v("0.856200")]),t._v(" "),s("td",[t._v("00:22")])])])]),t._v(" "),s("p",[t._v("As you can see, migrating from Ignite allowed us to replace 52 lines of code (in "),s("code",[t._v("run()")]),t._v(") with just 3 lines, and doesn't require you to change any of your existing data pipelines, optimizers, loss functions, models, etc. Once you've made this change, you can then benefit from fastai's rich set of callbacks, transforms, visualizations, and so forth.")]),t._v(" "),s("p",[t._v("Note that fastai is very different from Ignite, in that it is much more than just a training loop (although we're only using the training loop in this example) - it is a complete framework including GPU-accelerated transformations, end-to-end inference, integrated applications for vision, text, tabular, and collaborative filtering, and so forth. You can use any part of the framework on its own, or combine them together, as described in the "),s("a",{attrs:{href:"https://arxiv.org/abs/2002.04688",target:"_blank",rel:"noopener noreferrer"}},[t._v("fastai paper"),s("OutboundLink")],1),t._v(".")])])}),[],!1,null,null,null);a.default=e.exports}}]);