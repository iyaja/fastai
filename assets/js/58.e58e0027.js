(window.webpackJsonp=window.webpackJsonp||[]).push([[58],{419:function(t,a,s){"use strict";s.r(a);var e=s(42),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"tutorial-binary-classification-of-chest-x-rays"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tutorial-binary-classification-of-chest-x-rays"}},[t._v("#")]),t._v(" Tutorial - Binary classification of chest X-rays")]),t._v(" "),s("blockquote",[s("p",[t._v("In this tutorial we will build a classifier that distinguishes between chest X-rays with pneumothorax and chest X-rays without pneumothorax. The image data is loaded directly from the DICOM source files, so no prior DICOM data handling is needed.")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("basics "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("callback"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("all")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("all")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("medical"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imaging "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pydicom\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n")])])]),s("p",[t._v("To use "),s("code",[t._v("fastai.medical.imaging")]),t._v(" you'll need to:")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("conda "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" pyarrow\npip "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" pydicom kornia opencv-python scikit-image\n")])])]),s("h2",{attrs:{id:"download-and-import-of-x-ray-dicom-files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#download-and-import-of-x-ray-dicom-files"}},[t._v("#")]),t._v(" Download and import of X-ray DICOM files")]),t._v(" "),s("p",[t._v("First, we will use the "),s("RouterLink",{attrs:{to:"/data.external.html#untar_data"}},[s("code",[t._v("untar_data")])]),t._v(" function to download the "),s("em",[t._v("siim_small")]),t._v(" folder containing a subset (250 DICOM files, ~30MB) of the "),s("a",{attrs:{href:"https://doi.org/10.1007/s10278-019-00299-9",target:"_blank",rel:"noopener noreferrer"}},[t._v("SIIM-ACR Pneumothorax Segmentation"),s("OutboundLink")],1),t._v(" [1] dataset.\nThe downloaded "),s("em",[t._v("siim_small")]),t._v(" folder will be stored in your "),s("em",[t._v("~/.fastai/data/")]),t._v(" directory. The variable "),s("code",[t._v("pneumothorax-source")]),t._v(" will store the absolute path to the "),s("em",[t._v("siim_small")]),t._v(" folder as soon as the download is complete.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("pneumothorax_source "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SIIM_SMALL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("em",[t._v("siim_small")]),t._v(" folder has the following directory/file structure:")]),t._v(" "),s("p",[s("img",{attrs:{src:"/images/siim_folder_structure.jpeg",alt:"siim_folder_structure.jpg"}})]),t._v(" "),s("h3",{attrs:{id:"plotting-the-dicom-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#plotting-the-dicom-data"}},[t._v("#")]),t._v(" Plotting the DICOM data")]),t._v(" "),s("p",[t._v("To analyze our dataset, we load the paths to the DICOM files with the "),s("RouterLink",{attrs:{to:"/medical.imaging.html#get_dicom_files"}},[s("code",[t._v("get_dicom_files")])]),t._v(" function. When calling the function, we append "),s("em",[t._v("train/")]),t._v(" to the "),s("code",[t._v("pneumothorax_source")]),t._v(" path to choose the folder where the DICOM files are located. We store the path to each DICOM file in the "),s("code",[t._v("items")]),t._v(" list.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("items "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_dicom_files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pneumothorax_source"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"train/"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Next, we split the "),s("code",[t._v("items")]),t._v(" list into a train "),s("code",[t._v("trn")]),t._v(" and validation "),s("code",[t._v("val")]),t._v(" list using the "),s("RouterLink",{attrs:{to:"/data.transforms.html#RandomSplitter"}},[s("code",[t._v("RandomSplitter")])]),t._v(" function:")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("trn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RandomSplitter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("To plot an X-ray, we can select an entry in the "),s("code",[t._v("items")]),t._v(" list and load the DICOM file with "),s("code",[t._v("dcmread")]),t._v(". Then, we can plot it with the function "),s("code",[t._v("show")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("patient "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\nxray_sample "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dcmread"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("patient"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nxray_sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"output_14_0.png",alt:"png"}})]),t._v(" "),s("p",[t._v("Next, we need to load the labels for the dataset. We import the "),s("em",[t._v("labels.csv")]),t._v(" file using pandas and print the first five entries. The "),s("strong",[t._v("file")]),t._v(" column shows the relative path to the "),s("em",[t._v(".dcm")]),t._v(" file and the "),s("strong",[t._v("label")]),t._v(" column indicates whether the chest x-ray has a pneumothorax or not.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pneumothorax_source"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"labels.csv"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",[s("style",{attrs:{scoped:""}},[t._v('\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\x3c!--beforebegin--\x3e<div class="language- extra-class">\x3c!--afterbegin--\x3e<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n\x3c!--beforeend--\x3e</div>\x3c!--afterend--\x3e')]),t._v(" "),s("table",{staticClass:"dataframe",attrs:{border:"1"}},[s("thead",[s("tr",{staticStyle:{"text-align":"right"}},[s("th"),t._v(" "),s("th",[t._v("file")]),t._v(" "),s("th",[t._v("label")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("0")]),t._v(" "),s("td",[t._v("train/No Pneumothorax/000000.dcm")]),t._v(" "),s("td",[t._v("No Pneumothorax")])]),t._v(" "),s("tr",[s("td",[t._v("1")]),t._v(" "),s("td",[t._v("train/Pneumothorax/000001.dcm")]),t._v(" "),s("td",[t._v("Pneumothorax")])]),t._v(" "),s("tr",[s("td",[t._v("2")]),t._v(" "),s("td",[t._v("train/No Pneumothorax/000002.dcm")]),t._v(" "),s("td",[t._v("No Pneumothorax")])]),t._v(" "),s("tr",[s("td",[t._v("3")]),t._v(" "),s("td",[t._v("train/Pneumothorax/000003.dcm")]),t._v(" "),s("td",[t._v("Pneumothorax")])]),t._v(" "),s("tr",[s("td",[t._v("4")]),t._v(" "),s("td",[t._v("train/Pneumothorax/000004.dcm")]),t._v(" "),s("td",[t._v("Pneumothorax")])])])])]),t._v(" "),s("p",[t._v("Now, we use the "),s("RouterLink",{attrs:{to:"/data.block.html#DataBlock"}},[s("code",[t._v("DataBlock")])]),t._v(" class to prepare the DICOM data for training.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("pneumothorax "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DataBlock"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("blocks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ImageBlock"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cls"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PILDicom"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" CategoryBlock"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   get_x"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("pneumothorax_source"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   get_y"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   batch_tfms"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("aug_transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Additionally, we plot a first batch with the specified transformations:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("dls "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pneumothorax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"output_20_0.png",alt:"png"}})]),t._v(" "),s("h2",{attrs:{id:"training"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#training"}},[t._v("#")]),t._v(" Training")]),t._v(" "),s("p",[t._v("We can then use the "),s("RouterLink",{attrs:{to:"/vision.learner.html#cnn_learner"}},[s("code",[t._v("cnn_learner")])]),t._v(" function and initiate the training.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("learn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cnn_learner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" resnet34"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metrics"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("accuracy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_one_cycle"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("table",{staticClass:"dataframe",attrs:{border:"1"}},[s("thead",[s("tr",{staticStyle:{"text-align":"left"}},[s("th",[t._v("epoch")]),t._v(" "),s("th",[t._v("train_loss")]),t._v(" "),s("th",[t._v("valid_loss")]),t._v(" "),s("th",[t._v("accuracy")]),t._v(" "),s("th",[t._v("time")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("0")]),t._v(" "),s("td",[t._v("1.250138")]),t._v(" "),s("td",[t._v("1.026524")]),t._v(" "),s("td",[t._v("0.560000")]),t._v(" "),s("td",[t._v("00:03")])])])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pneumothorax_source"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"train/Pneumothorax/000004.dcm"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[t._v("('Pneumothorax', tensor(1), tensor([0.2858, 0.7142]))\n")])])]),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("tta "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("use_max"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",[s("style",[t._v("\n        /* Turns off some styling */\n        progress {\n            /* gets rid of default border in Firefox and Opera. */\n            border: none;\n            /* Needs to be in here for Safari polyfill so background images work as expected. */\n            background-size: auto;\n        }\n        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n            background: #F44336;\n        }\n    ")]),t._v(" "),s("progress",{staticStyle:{width:"300px",height:"20px","vertical-align":"middle"},attrs:{value:"4",max:"4",",":""}}),t._v("\n  100.00% [4/4 00:02<00:00]\n")]),t._v(" "),s("div",[s("style",[t._v("\n        /* Turns off some styling */\n        progress {\n            /* gets rid of default border in Firefox and Opera. */\n            border: none;\n            /* Needs to be in here for Safari polyfill so background images work as expected. */\n            background-size: auto;\n        }\n        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n            background: #F44336;\n        }\n    ")]),t._v(" "),s("progress",{staticStyle:{width:"300px",height:"20px","vertical-align":"middle"},attrs:{value:"1",max:"1",",":""}}),t._v("\n  100.00% [1/1 00:00<00:00]\n")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show_results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"output_26_1.png",alt:"png"}})]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("interp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Interpretation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_learner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("interp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot_top_losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("img",{attrs:{src:"output_28_0.png",alt:"png"}})]),t._v(" "),s("p",[s("em",[s("strong",[t._v("Citations:")])])]),t._v(" "),s("p",[t._v("[1] "),s("em",[t._v("Filice R et al. Crowdsourcing pneumothorax annotations using machine learning annotations on the NIH chest X-ray dataset.  J Digit Imaging (2019). https://doi.org/10.1007/s10278-019-00299-9")])])])}),[],!1,null,null,null);a.default=n.exports}}]);