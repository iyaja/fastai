(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{402:function(t,a,s){"use strict";s.r(a);var n=s(42),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"cutmix-callback"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cutmix-callback"}},[t._v("#")]),t._v(" CutMix Callback")]),t._v(" "),s("blockquote",[s("p",[t._v("Callback to apply "),s("a",{attrs:{href:"https://arxiv.org/pdf/1905.04899.pdf"}},[t._v("CutMix")]),t._v(" data augmentation technique to the training data.")])]),t._v(" "),s("p",[t._v("From the "),s("a",{attrs:{href:"https://arxiv.org/pdf/1905.04899.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("research paper"),s("OutboundLink")],1),t._v(", "),s("RouterLink",{attrs:{to:"/callback.cutmix.html#CutMix"}},[s("code",[t._v("CutMix")])]),t._v(" is a way to combine two images. It comes from "),s("RouterLink",{attrs:{to:"/callback.mixup.html#MixUp"}},[s("code",[t._v("MixUp")])]),t._v(" and "),s("code",[t._v("Cutout")]),t._v(". In this data augmentation technique:")],1),t._v(" "),s("blockquote",[s("p",[t._v("patches are cut and pasted among training images where the ground truth labels are also mixed proportionally to the area of the patches")])]),t._v(" "),s("p",[t._v("Also, from the paper:> By making efficient use of training pixels and retaining the regularization effect of regional dropout, CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly-supervised localization task. Moreover, unlike previous augmentation methods, our CutMix-trained ImageNet classifier, when used as a pretrained model, results in consistent performance gains in Pascal detection and MS-COCO image captioning benchmarks. We also show that CutMix improves the model robustness against input corruptions and its out-of-distribution detection performances.")]),t._v(" "),s("h2",{staticClass:"doc_header",attrs:{id:"CutMix"}},[s("code",[t._v("class")]),t._v(" "),s("code",[t._v("CutMix")]),s("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/callback/cutmix.py#L10"}},[t._v("[source]")])]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("CutMix")]),t._v("("),s("strong",[s("code",[t._v("alpha")])]),t._v("="),s("em",[s("code",[t._v("1.0")])]),t._v(") :: "),s("RouterLink",{attrs:{to:"/callback.core.html#Callback"}},[s("code",[t._v("Callback")])])],1)]),t._v(" "),s("p",[t._v("Implementation of "),s("code",[t._v("https://arxiv.org/abs/1905.04899")])]),t._v(" "),s("h2",{attrs:{id:"how-does-the-batch-with-cutmix-data-augmentation-technique-look-like"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#how-does-the-batch-with-cutmix-data-augmentation-technique-look-like"}},[t._v("#")]),t._v(" How does the batch with "),s("RouterLink",{attrs:{to:"/callback.cutmix.html#CutMix"}},[s("code",[t._v("CutMix")])]),t._v(" data augmentation technique look like?")],1),t._v(" "),s("p",[t._v("First, let's quickly create the "),s("code",[t._v("dls")]),t._v(" using "),s("RouterLink",{attrs:{to:"/vision.data.html#ImageDataLoaders.from_name_re"}},[s("code",[t._v("ImageDataLoaders.from_name_re")])]),t._v(" DataBlocks API.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npat        "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'([^/]+)_\\d+.*$'")]),t._v("\nfnames     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_image_files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nitem_tfms  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" method"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'crop'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nbatch_tfms "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("aug_transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_stats"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("imagenet_stats"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ndls "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ImageDataLoaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_name_re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fnames"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item_tfms"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("item_tfms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                    batch_tfms"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("batch_tfms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Next, let's initialize the callback "),s("RouterLink",{attrs:{to:"/callback.cutmix.html#CutMix"}},[s("code",[t._v("CutMix")])]),t._v(", create a learner, do one batch and display the images with the labels. "),s("RouterLink",{attrs:{to:"/callback.cutmix.html#CutMix"}},[s("code",[t._v("CutMix")])]),t._v(" inside updates the loss function based on the ratio of the cutout bbox to the complete image.")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("cutmix "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CutMix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("alpha"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" Learner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" resnet18"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("CrossEntropyLossFlat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cbs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cutmix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epoch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("training "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n    learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dl "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train\n    b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("one_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    learn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'before_batch'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("axs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" figsize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cutmix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cutmix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ctxs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("axs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("table",{staticClass:"dataframe",attrs:{border:"1"}},[s("thead",[s("tr",{staticStyle:{"text-align":"left"}},[s("th",[t._v("epoch")]),t._v(" "),s("th",[t._v("train_loss")]),t._v(" "),s("th",[t._v("valid_loss")]),t._v(" "),s("th",[t._v("time")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("0")]),t._v(" "),s("td",[t._v("00:00")])])])]),t._v(" "),s("p",[s("img",{attrs:{src:"output_10_1.png",alt:"png"}})]),t._v(" "),s("h2",{attrs:{id:"using-cutmix-in-training"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#using-cutmix-in-training"}},[t._v("#")]),t._v(" Using "),s("RouterLink",{attrs:{to:"/callback.cutmix.html#CutMix"}},[s("code",[t._v("CutMix")])]),t._v(" in Training")],1),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("learn "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cnn_learner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dls"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" resnet18"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_func"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("CrossEntropyLossFlat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cbs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cutmix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metrics"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("accuracy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" error_rate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# learn.fit_one_cycle(1)")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);