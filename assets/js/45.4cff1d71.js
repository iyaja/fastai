(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{381:function(t,e,a){"use strict";a.r(e);var s=a(42),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"learner-for-the-text-application"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#learner-for-the-text-application"}},[t._v("#")]),t._v(" Learner for the text application")]),t._v(" "),a("blockquote",[a("p",[t._v("All the functions necessary to build "),a("code",[t._v("Learner")]),t._v(" suitable for transfer learning in NLP")])]),t._v(" "),a("p",[t._v("The most important functions of this module are "),a("RouterLink",{attrs:{to:"/text.learner.html#language_model_learner"}},[a("code",[t._v("language_model_learner")])]),t._v(" and "),a("RouterLink",{attrs:{to:"/text.learner.html#text_classifier_learner"}},[a("code",[t._v("text_classifier_learner")])]),t._v(". They will help you define a "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" using a pretrained model. See the "),a("a",{attrs:{href:"http://docs.fast.ai/tutorial.text",target:"_blank",rel:"noopener noreferrer"}},[t._v("text tutorial"),a("OutboundLink")],1),t._v(" for exmaples of use.")],1),t._v(" "),a("h2",{attrs:{id:"loading-a-pretrained-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loading-a-pretrained-model"}},[t._v("#")]),t._v(" Loading a pretrained model")]),t._v(" "),a("p",[t._v("In text, to load a pretrained model, we need to adapt the embeddings of the vocabulary used for the pre-training to the vocabulary of our current corpus.")]),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"match_embeds"}},[a("code",[t._v("match_embeds")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L16"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("match_embeds")]),t._v("("),a("strong",[a("code",[t._v("old_wgts")])]),t._v(", "),a("strong",[a("code",[t._v("old_vocab")])]),t._v(", "),a("strong",[a("code",[t._v("new_vocab")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Convert the embedding in "),a("code",[t._v("old_wgts")]),t._v(" to go from "),a("code",[t._v("old_vocab")]),t._v(" to "),a("code",[t._v("new_vocab")]),t._v(".")]),t._v(" "),a("p",[t._v("For words in "),a("code",[t._v("new_vocab")]),t._v(" that don't have a corresponding match in "),a("code",[t._v("old_vocab")]),t._v(", we use the mean of all pretrained embeddings.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("wgts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.encoder.weight'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nnew_wgts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" match_embeds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wgts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("copy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nold"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("new "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wgts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.encoder.weight'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("new_wgts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.encoder.weight'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" old"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h4",{staticClass:"doc_header",attrs:{id:"load_ignore_keys"}},[a("code",[t._v("load_ignore_keys")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L42"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("load_ignore_keys")]),t._v("("),a("strong",[a("code",[t._v("model")])]),t._v(", "),a("strong",[a("code",[t._v("wgts")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Load "),a("code",[t._v("wgts")]),t._v(" in "),a("code",[t._v("model")]),t._v(" ignoring the names of the keys, just taking parameters in order")]),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"clean_raw_keys"}},[a("code",[t._v("clean_raw_keys")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L59"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("clean_raw_keys")]),t._v("("),a("strong",[a("code",[t._v("wgts")])]),t._v(")")])]),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"load_model_text"}},[a("code",[t._v("load_model_text")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L68"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("load_model_text")]),t._v("("),a("strong",[a("code",[t._v("file")])]),t._v(", "),a("strong",[a("code",[t._v("model")])]),t._v(", "),a("strong",[a("code",[t._v("opt")])]),t._v(", "),a("strong",[a("code",[t._v("with_opt")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("device")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("strict")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Load "),a("code",[t._v("model")]),t._v(" from "),a("code",[t._v("file")]),t._v(" along with "),a("code",[t._v("opt")]),t._v(" (if available, and if "),a("code",[t._v("with_opt")]),t._v(")")]),t._v(" "),a("h2",{staticClass:"doc_header",attrs:{id:"TextLearner"}},[a("code",[t._v("class")]),t._v(" "),a("code",[t._v("TextLearner")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L86"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("TextLearner")]),t._v("("),a("strong",[a("code",[t._v("dls")])]),t._v(", "),a("strong",[a("code",[t._v("model")])]),t._v(", "),a("strong",[a("code",[t._v("alpha")])]),t._v("="),a("em",[a("code",[t._v("2.0")])]),t._v(", "),a("strong",[a("code",[t._v("beta")])]),t._v("="),a("em",[a("code",[t._v("1.0")])]),t._v(", "),a("strong",[a("code",[t._v("moms")])]),t._v("="),a("em",[a("code",[t._v("(0.8, 0.7, 0.8)")])]),t._v(", "),a("strong",[a("code",[t._v("loss_func")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("opt_func")])]),t._v("="),a("em",[a("code",[t._v("Adam")])]),t._v(", "),a("strong",[a("code",[t._v("lr")])]),t._v("="),a("em",[a("code",[t._v("0.001")])]),t._v(", "),a("strong",[a("code",[t._v("splitter")])]),t._v("="),a("em",[a("code",[t._v("trainable_params")])]),t._v(", "),a("strong",[a("code",[t._v("cbs")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("metrics")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("path")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("model_dir")])]),t._v("="),a("em",[a("code",[t._v("'models'")])]),t._v(", "),a("strong",[a("code",[t._v("wd")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("wd_bn_bias")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("train_bn")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(") :: "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])])],1)]),t._v(" "),a("p",[t._v("Basic class for a "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" in NLP.")],1),t._v(" "),a("p",[t._v("Adds a "),a("RouterLink",{attrs:{to:"/callback.rnn.html#ModelResetter"}},[a("code",[t._v("ModelResetter")])]),t._v(" and an "),a("RouterLink",{attrs:{to:"/callback.rnn.html#RNNRegularizer"}},[a("code",[t._v("RNNRegularizer")])]),t._v(" with "),a("code",[t._v("alpha")]),t._v(" and "),a("code",[t._v("beta")]),t._v(" to the callbacks, the rest is the same as "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" init.")],1),t._v(" "),a("p",[t._v("This "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" adds functionality to the base class:")],1),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"TextLearner.load_pretrained"}},[a("code",[t._v("TextLearner.load_pretrained")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L110"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("TextLearner.load_pretrained")]),t._v("("),a("strong",[a("code",[t._v("wgts_fname")])]),t._v(", "),a("strong",[a("code",[t._v("vocab_fname")])]),t._v(", "),a("strong",[a("code",[t._v("model")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Load a pretrained model and adapt it to the data vocabulary.")]),t._v(" "),a("p",[a("code",[t._v("wgts_fname")]),t._v(" should point to the weights of the pretrained model and "),a("code",[t._v("vocab_fname")]),t._v(" to the vocabulary used to pretrain it.")]),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"TextLearner.save_encoder"}},[a("code",[t._v("TextLearner.save_encoder")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L92"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("TextLearner.save_encoder")]),t._v("("),a("strong",[a("code",[t._v("file")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Save the encoder to "),a("code",[t._v("file")]),t._v(" in the model directory")]),t._v(" "),a("p",[t._v("The model directory is "),a("RouterLink",{attrs:{to:"/learner.html#Learner.path/Learner.model_dir"}},[a("code",[t._v("Learner.path/Learner.model_dir")])]),t._v(".")],1),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"TextLearner.load_encoder"}},[a("code",[t._v("TextLearner.load_encoder")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L99"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("TextLearner.load_encoder")]),t._v("("),a("strong",[a("code",[t._v("file")])]),t._v(", "),a("strong",[a("code",[t._v("device")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Load the encoder "),a("code",[t._v("file")]),t._v(" from the model directory, optionally ensuring it's on "),a("code",[t._v("device")])]),t._v(" "),a("h2",{attrs:{id:"language-modeling-predictions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#language-modeling-predictions"}},[t._v("#")]),t._v(" Language modeling predictions")]),t._v(" "),a("p",[t._v("For language modeling, the predict method is quite different form the other applications, which is why it needs its own subclass.")]),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"decode_spec_tokens"}},[a("code",[t._v("decode_spec_tokens")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L132"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("decode_spec_tokens")]),t._v("("),a("strong",[a("code",[t._v("tokens")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Decode the special tokens in "),a("code",[t._v("tokens")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("test_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("decode_spec_tokens"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxmaj'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("decode_spec_tokens"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxup'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TEXT'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("decode_spec_tokens"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxrep'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'aaa'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_eq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("decode_spec_tokens"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxwrep'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'word'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'word'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'word'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'word'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{staticClass:"doc_header",attrs:{id:"LMLearner"}},[a("code",[t._v("class")]),t._v(" "),a("code",[t._v("LMLearner")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L154"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("LMLearner")]),t._v("("),a("strong",[a("code",[t._v("dls")])]),t._v(", "),a("strong",[a("code",[t._v("model")])]),t._v(", "),a("strong",[a("code",[t._v("alpha")])]),t._v("="),a("em",[a("code",[t._v("2.0")])]),t._v(", "),a("strong",[a("code",[t._v("beta")])]),t._v("="),a("em",[a("code",[t._v("1.0")])]),t._v(", "),a("strong",[a("code",[t._v("moms")])]),t._v("="),a("em",[a("code",[t._v("(0.8, 0.7, 0.8)")])]),t._v(", "),a("strong",[a("code",[t._v("loss_func")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("opt_func")])]),t._v("="),a("em",[a("code",[t._v("Adam")])]),t._v(", "),a("strong",[a("code",[t._v("lr")])]),t._v("="),a("em",[a("code",[t._v("0.001")])]),t._v(", "),a("strong",[a("code",[t._v("splitter")])]),t._v("="),a("em",[a("code",[t._v("trainable_params")])]),t._v(", "),a("strong",[a("code",[t._v("cbs")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("metrics")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("path")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("model_dir")])]),t._v("="),a("em",[a("code",[t._v("'models'")])]),t._v(", "),a("strong",[a("code",[t._v("wd")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("wd_bn_bias")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("train_bn")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(") :: "),a("RouterLink",{attrs:{to:"/text.learner.html#TextLearner"}},[a("code",[t._v("TextLearner")])])],1)]),t._v(" "),a("p",[t._v("Add functionality to "),a("RouterLink",{attrs:{to:"/text.learner.html#TextLearner"}},[a("code",[t._v("TextLearner")])]),t._v(" when dealingwith a language model")],1),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"LMLearner.predict"}},[a("code",[t._v("LMLearner.predict")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L156"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("LMLearner.predict")]),t._v("("),a("strong",[a("code",[t._v("text")])]),t._v(", "),a("strong",[a("code",[t._v("n_words")])]),t._v("="),a("em",[a("code",[t._v("1")])]),t._v(", "),a("strong",[a("code",[t._v("no_unk")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(", "),a("strong",[a("code",[t._v("temperature")])]),t._v("="),a("em",[a("code",[t._v("1.0")])]),t._v(", "),a("strong",[a("code",[t._v("min_p")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("no_bar")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("decoder")])]),t._v("="),a("em",[a("code",[t._v("decode_spec_tokens")])]),t._v(", "),a("strong",[a("code",[t._v("only_last_word")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Return "),a("code",[t._v("text")]),t._v(" and the "),a("code",[t._v("n_words")]),t._v(" that come after")]),t._v(" "),a("p",[t._v("The words are picked randomly among the predictions, depending on the probability of each index. "),a("code",[t._v("no_unk")]),t._v(" means we never pick the "),a("code",[t._v("UNK")]),t._v(" token, "),a("code",[t._v("temperature")]),t._v(" is applied to the predictions, if "),a("code",[t._v("min_p")]),t._v(" is passed, we don't consider the indices with a probability lower than it. Set "),a("code",[t._v("no_bar")]),t._v(" to "),a("code",[t._v("True")]),t._v(" if you don't want any progress bar, and you can pass a long a custom "),a("code",[t._v("decoder")]),t._v(" to process the predicted tokens.")]),t._v(" "),a("h2",{attrs:{id:"learner-convenience-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#learner-convenience-functions"}},[t._v("#")]),t._v(" "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" convenience functions")],1),t._v(" "),a("h4",{staticClass:"doc_header",attrs:{id:"language_model_learner"}},[a("code",[t._v("language_model_learner")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L193"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("language_model_learner")]),t._v("("),a("strong",[a("code",[t._v("dls")])]),t._v(", "),a("strong",[a("code",[t._v("arch")])]),t._v(", "),a("strong",[a("code",[t._v("config")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("drop_mult")])]),t._v("="),a("em",[a("code",[t._v("1.0")])]),t._v(", "),a("strong",[a("code",[t._v("backwards")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("pretrained")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(", "),a("strong",[a("code",[t._v("pretrained_fnames")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("loss_func")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("opt_func")])]),t._v("="),a("em",[a("code",[t._v("Adam")])]),t._v(", "),a("strong",[a("code",[t._v("lr")])]),t._v("="),a("em",[a("code",[t._v("0.001")])]),t._v(", "),a("strong",[a("code",[t._v("splitter")])]),t._v("="),a("em",[a("code",[t._v("trainable_params")])]),t._v(", "),a("strong",[a("code",[t._v("cbs")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("metrics")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("path")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("model_dir")])]),t._v("="),a("em",[a("code",[t._v("'models'")])]),t._v(", "),a("strong",[a("code",[t._v("wd")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("wd_bn_bias")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("train_bn")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(", "),a("strong",[a("code",[t._v("moms")])]),t._v("="),a("em",[a("code",[t._v("(0.95, 0.85, 0.95)")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Create a "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" with a language model from "),a("code",[t._v("dls")]),t._v(" and "),a("code",[t._v("arch")]),t._v(".")],1),t._v(" "),a("p",[t._v("You can use the "),a("code",[t._v("config")]),t._v(" to customize the architecture used (change the values from "),a("RouterLink",{attrs:{to:"/text.models.awdlstm.html#awd_lstm_lm_config"}},[a("code",[t._v("awd_lstm_lm_config")])]),t._v(" for this), "),a("code",[t._v("pretrained")]),t._v(" will use fastai's pretrained model for this "),a("code",[t._v("arch")]),t._v(" (if available) or you can pass specific "),a("code",[t._v("pretrained_fnames")]),t._v(" containing your own pretrained model and the corresponding vocabulary. All other arguments are passed to "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(".")],1),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("IMDB_SAMPLE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'texts.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TextDataLoaders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text_col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_lm"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" valid_col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'is_valid'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" language_model_learner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dls"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AWD_LSTM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("You can then use the "),a("code",[t._v(".predict")]),t._v(" method to generate new text.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'This movie is about'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_words"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("'This movie is about front - line highlights for fifteen United States Navy and the US Navy , four'\n")])])]),a("p",[t._v("By default the entire sentence is feed again to the model after each predicted word, this little trick shows an improvement on the quality of the generated text. If you want to feed only the last word, specify argument "),a("code",[t._v("only_last_word")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("learn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'This movie is about'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_words"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" only_last_word"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("'This movie is about 6 No person in Suppose he was used searching for the late in West of other important'\n")])])]),a("h4",{staticClass:"doc_header",attrs:{id:"text_classifier_learner"}},[a("code",[t._v("text_classifier_learner")]),a("a",{staticClass:"source_link",staticStyle:{float:"right"},attrs:{href:"https://github.com/fastai/fastai/tree/master/fastai/text/learner.py#L215"}},[t._v("[source]")])]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("text_classifier_learner")]),t._v("("),a("strong",[a("code",[t._v("dls")])]),t._v(", "),a("strong",[a("code",[t._v("arch")])]),t._v(", "),a("strong",[a("code",[t._v("seq_len")])]),t._v("="),a("em",[a("code",[t._v("72")])]),t._v(", "),a("strong",[a("code",[t._v("config")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("backwards")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("pretrained")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(", "),a("strong",[a("code",[t._v("drop_mult")])]),t._v("="),a("em",[a("code",[t._v("0.5")])]),t._v(", "),a("strong",[a("code",[t._v("n_out")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("lin_ftrs")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("ps")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("max_len")])]),t._v("="),a("em",[a("code",[t._v("1440")])]),t._v(", "),a("strong",[a("code",[t._v("y_range")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("loss_func")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("opt_func")])]),t._v("="),a("em",[a("code",[t._v("Adam")])]),t._v(", "),a("strong",[a("code",[t._v("lr")])]),t._v("="),a("em",[a("code",[t._v("0.001")])]),t._v(", "),a("strong",[a("code",[t._v("splitter")])]),t._v("="),a("em",[a("code",[t._v("trainable_params")])]),t._v(", "),a("strong",[a("code",[t._v("cbs")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("metrics")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("path")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("model_dir")])]),t._v("="),a("em",[a("code",[t._v("'models'")])]),t._v(", "),a("strong",[a("code",[t._v("wd")])]),t._v("="),a("em",[a("code",[t._v("None")])]),t._v(", "),a("strong",[a("code",[t._v("wd_bn_bias")])]),t._v("="),a("em",[a("code",[t._v("False")])]),t._v(", "),a("strong",[a("code",[t._v("train_bn")])]),t._v("="),a("em",[a("code",[t._v("True")])]),t._v(", "),a("strong",[a("code",[t._v("moms")])]),t._v("="),a("em",[a("code",[t._v("(0.95, 0.85, 0.95)")])]),t._v(")")])]),t._v(" "),a("p",[t._v("Create a "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(" with a text classifier from "),a("code",[t._v("dls")]),t._v(" and "),a("code",[t._v("arch")]),t._v(".")],1),t._v(" "),a("p",[t._v("You can use the "),a("code",[t._v("config")]),t._v(" to customize the architecture used (change the values from "),a("RouterLink",{attrs:{to:"/text.models.awdlstm.html#awd_lstm_clas_config"}},[a("code",[t._v("awd_lstm_clas_config")])]),t._v(" for this), "),a("code",[t._v("pretrained")]),t._v(" will use fastai's pretrained model for this "),a("code",[t._v("arch")]),t._v(" (if available). "),a("code",[t._v("drop_mult")]),t._v(" is a global multiplier applied to control all dropouts. "),a("code",[t._v("n_out")]),t._v(" is usually inferred from the "),a("code",[t._v("dls")]),t._v(" but you may pass it.")],1),t._v(" "),a("p",[t._v("The model uses a "),a("RouterLink",{attrs:{to:"/text.models.core.html#SentenceEncoder"}},[a("code",[t._v("SentenceEncoder")])]),t._v(", which means the texts are passed "),a("code",[t._v("seq_len")]),t._v(" tokens at a time, and will only compute the gradients on the last "),a("code",[t._v("max_len")]),t._v(" steps. "),a("code",[t._v("lin_ftrs")]),t._v(" and "),a("code",[t._v("ps")]),t._v(" are passed to "),a("RouterLink",{attrs:{to:"/text.models.core.html#get_text_classifier"}},[a("code",[t._v("get_text_classifier")])]),t._v(".")],1),t._v(" "),a("p",[t._v("All other arguments are passed to "),a("RouterLink",{attrs:{to:"/learner.html#Learner"}},[a("code",[t._v("Learner")])]),t._v(".")],1),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("IMDB_SAMPLE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'texts.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TextDataLoaders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text_col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label_col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'label'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" valid_col"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'is_valid'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" text_classifier_learner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dls"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AWD_LSTM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);e.default=n.exports}}]);