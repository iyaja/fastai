<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Tutorial - Transformers</title>
    <meta name="generator" content="VuePress 1.5.4">
    
    <meta name="description" content="Welcome to fastai">
    <link rel="preload" href="/fastai/assets/css/0.styles.24b54ae9.css" as="style"><link rel="preload" href="/fastai/assets/js/app.e4c088e4.js" as="script"><link rel="preload" href="/fastai/assets/js/2.f1c4f916.js" as="script"><link rel="preload" href="/fastai/assets/js/63.a3aa571a.js" as="script"><link rel="prefetch" href="/fastai/assets/js/10.99994145.js"><link rel="prefetch" href="/fastai/assets/js/11.08687312.js"><link rel="prefetch" href="/fastai/assets/js/12.40b88a98.js"><link rel="prefetch" href="/fastai/assets/js/13.83861397.js"><link rel="prefetch" href="/fastai/assets/js/14.3a1586b8.js"><link rel="prefetch" href="/fastai/assets/js/15.1cbd093c.js"><link rel="prefetch" href="/fastai/assets/js/16.c850565b.js"><link rel="prefetch" href="/fastai/assets/js/17.9c3f07b2.js"><link rel="prefetch" href="/fastai/assets/js/18.db37b5bb.js"><link rel="prefetch" href="/fastai/assets/js/19.c91272fe.js"><link rel="prefetch" href="/fastai/assets/js/20.a9c5f90d.js"><link rel="prefetch" href="/fastai/assets/js/21.e40307f7.js"><link rel="prefetch" href="/fastai/assets/js/22.8fcdc465.js"><link rel="prefetch" href="/fastai/assets/js/23.14fb4a2d.js"><link rel="prefetch" href="/fastai/assets/js/24.720b52ea.js"><link rel="prefetch" href="/fastai/assets/js/25.7912d1b1.js"><link rel="prefetch" href="/fastai/assets/js/26.366239e0.js"><link rel="prefetch" href="/fastai/assets/js/27.6db2df9e.js"><link rel="prefetch" href="/fastai/assets/js/28.ffbcb114.js"><link rel="prefetch" href="/fastai/assets/js/29.7b21b9fd.js"><link rel="prefetch" href="/fastai/assets/js/3.6e2ab6c3.js"><link rel="prefetch" href="/fastai/assets/js/30.248393fd.js"><link rel="prefetch" href="/fastai/assets/js/31.b22a56a0.js"><link rel="prefetch" href="/fastai/assets/js/32.85f7da41.js"><link rel="prefetch" href="/fastai/assets/js/33.e44ef8ee.js"><link rel="prefetch" href="/fastai/assets/js/34.9ce56e10.js"><link rel="prefetch" href="/fastai/assets/js/35.4bdc5816.js"><link rel="prefetch" href="/fastai/assets/js/36.67e5f7d9.js"><link rel="prefetch" href="/fastai/assets/js/37.36c20575.js"><link rel="prefetch" href="/fastai/assets/js/38.06c462ff.js"><link rel="prefetch" href="/fastai/assets/js/39.749b6672.js"><link rel="prefetch" href="/fastai/assets/js/4.a083dd6e.js"><link rel="prefetch" href="/fastai/assets/js/40.c732859b.js"><link rel="prefetch" href="/fastai/assets/js/41.4474ab47.js"><link rel="prefetch" href="/fastai/assets/js/42.5ee2fc2f.js"><link rel="prefetch" href="/fastai/assets/js/43.cc635513.js"><link rel="prefetch" href="/fastai/assets/js/44.152c8da5.js"><link rel="prefetch" href="/fastai/assets/js/45.4cff1d71.js"><link rel="prefetch" href="/fastai/assets/js/46.85dce95d.js"><link rel="prefetch" href="/fastai/assets/js/47.59fb5617.js"><link rel="prefetch" href="/fastai/assets/js/48.f20ef06e.js"><link rel="prefetch" href="/fastai/assets/js/49.9625880a.js"><link rel="prefetch" href="/fastai/assets/js/5.bb68e855.js"><link rel="prefetch" href="/fastai/assets/js/50.b2e6dee9.js"><link rel="prefetch" href="/fastai/assets/js/51.267442e2.js"><link rel="prefetch" href="/fastai/assets/js/52.10494ddd.js"><link rel="prefetch" href="/fastai/assets/js/53.093941a1.js"><link rel="prefetch" href="/fastai/assets/js/54.fbc03694.js"><link rel="prefetch" href="/fastai/assets/js/55.0b1efc19.js"><link rel="prefetch" href="/fastai/assets/js/56.5f3c1da5.js"><link rel="prefetch" href="/fastai/assets/js/57.a3e942a9.js"><link rel="prefetch" href="/fastai/assets/js/58.d3ded5e3.js"><link rel="prefetch" href="/fastai/assets/js/59.ec1d3156.js"><link rel="prefetch" href="/fastai/assets/js/6.f6c9602c.js"><link rel="prefetch" href="/fastai/assets/js/60.37aa0b8a.js"><link rel="prefetch" href="/fastai/assets/js/61.ef622343.js"><link rel="prefetch" href="/fastai/assets/js/62.e733d0f9.js"><link rel="prefetch" href="/fastai/assets/js/64.8b06642f.js"><link rel="prefetch" href="/fastai/assets/js/65.97cf2dfa.js"><link rel="prefetch" href="/fastai/assets/js/66.7f97711c.js"><link rel="prefetch" href="/fastai/assets/js/67.31ee059f.js"><link rel="prefetch" href="/fastai/assets/js/68.d013d2de.js"><link rel="prefetch" href="/fastai/assets/js/69.50b9f11d.js"><link rel="prefetch" href="/fastai/assets/js/7.c1cdf251.js"><link rel="prefetch" href="/fastai/assets/js/70.1b6f8370.js"><link rel="prefetch" href="/fastai/assets/js/71.8c3557b5.js"><link rel="prefetch" href="/fastai/assets/js/72.2d857b7b.js"><link rel="prefetch" href="/fastai/assets/js/73.0be86c71.js"><link rel="prefetch" href="/fastai/assets/js/74.a9279ff6.js"><link rel="prefetch" href="/fastai/assets/js/75.f6ce5fb3.js"><link rel="prefetch" href="/fastai/assets/js/8.be08f3ee.js"><link rel="prefetch" href="/fastai/assets/js/9.209ff10c.js">
    <link rel="stylesheet" href="/fastai/assets/css/0.styles.24b54ae9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/fastai/" class="home-link router-link-active"><img src="https://images.exxactcorp.com/CMS/landing-page/resource-center/supported-software/logo/Deep-Learning/fastai-logo.png" alt="" class="logo"> <!----></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Getting Started" class="dropdown-title"><span class="title">Getting Started</span> <span class="arrow down"></span></button> <button type="button" aria-label="Getting Started" class="mobile-dropdown-title"><span class="title">Getting Started</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><!----> <a href="/fastai/quick_start.html" class="nav-link">
  Quick Start
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tutorials" class="dropdown-title"><span class="title">Tutorials</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tutorials" class="mobile-dropdown-title"><span class="title">Tutorials</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tutorial/overview.html" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><h4>
          Beginners
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/vision.html" class="nav-link">
  Vision Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/text.html" class="nav-link">
  Text Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/tabular.html" class="nav-link">
  Tabular Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/colab.html" class="nav-link">
  Colab Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Intermediate
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/datablock.html" class="nav-link">
  Data Block Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/imagenette.html" class="nav-link">
  Imagenette Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/pets.html" class="nav-link">
  Pets Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/transformers.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  Transformers Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/wikitext.html" class="nav-link">
  Wikitext Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Advanced
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/siamese.html" class="nav-link">
  Siamese Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/dev-setup.html" class="nav-link">
  Developer Guide
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Training" class="dropdown-title"><span class="title">Training</span> <span class="arrow down"></span></button> <button type="button" aria-label="Training" class="mobile-dropdown-title"><span class="title">Training</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/training/learner.html" class="nav-link">
  Training Loop
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/optimizer.html" class="nav-link">
  Optimizer
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/metrics.html" class="nav-link">
  Metrics
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/interpret.html" class="nav-link">
  Interpretation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/distributed.html" class="nav-link">
  Distributed
</a></li><li class="dropdown-item"><h4>
          Callbacks
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/callback/core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/schedule.html" class="nav-link">
  Schedulers
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/hook.html" class="nav-link">
  Hooks and callbacks
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/fp16.html" class="nav-link">
  Mixed precision
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/mixup.html" class="nav-link">
  Mixup
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/cutmix.html" class="nav-link">
  Cutmix
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/tracker.html" class="nav-link">
  Tracker
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/training.html" class="nav-link">
  Training
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/rnn.html" class="nav-link">
  RNN
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/data.html" class="nav-link">
  Data
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/progress.html" class="nav-link">
  Progress
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Data" class="dropdown-title"><span class="title">Data</span> <span class="arrow down"></span></button> <button type="button" aria-label="Data" class="mobile-dropdown-title"><span class="title">Data</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/data/block.html" class="nav-link">
  Data Blocks
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/transforms.html" class="nav-link">
  Data Transforms
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/external.html" class="nav-link">
  Data External
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/core.html" class="nav-link">
  Data Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/load.html" class="nav-link">
  DataLoaders
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Core" class="dropdown-title"><span class="title">Core</span> <span class="arrow down"></span></button> <button type="button" aria-label="Core" class="mobile-dropdown-title"><span class="title">Core</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/torch_core.html" class="nav-link">
  PyTorch Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/layers.html" class="nav-link">
  Layers
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Vision" class="dropdown-title"><span class="title">Vision</span> <span class="arrow down"></span></button> <button type="button" aria-label="Vision" class="mobile-dropdown-title"><span class="title">Vision</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/vision/learner.html" class="nav-link">
  Vision Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/augment.html" class="nav-link">
  Vision Data Augmentation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/data.html" class="nav-link">
  Vision Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/core.html" class="nav-link">
  Vision Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/utils.html" class="nav-link">
  Vision Utils
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/widgets.html" class="nav-link">
  Vision Widgets
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/vision/models.xresnet.html" class="nav-link">
  XResNet
</a></li><li class="dropdown-subitem"><a href="/fastai/vision/models.unet.html" class="nav-link">
  UNet
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Text" class="dropdown-title"><span class="title">Text</span> <span class="arrow down"></span></button> <button type="button" aria-label="Text" class="mobile-dropdown-title"><span class="title">Text</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/text/core.html" class="nav-link">
  Text Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/data.html" class="nav-link">
  Text Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/learner.html" class="nav-link">
  Text Learner
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/text/models.core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.awdlstm.html" class="nav-link">
  AWD LSTM
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.qrnn.html" class="nav-link">
  QRNN
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tabular" class="dropdown-title"><span class="title">Tabular</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tabular" class="mobile-dropdown-title"><span class="title">Tabular</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tabular/core.html" class="nav-link">
  Tabular Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/data.html" class="nav-link">
  Tabular Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/learner.html" class="nav-link">
  Tabular Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/model.html" class="nav-link">
  Tabular Model
</a></li><li class="dropdown-item"><!----> <a href="/fastai/collab.html" class="nav-link">
  Collab
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Medical" class="dropdown-title"><span class="title">Medical</span> <span class="arrow down"></span></button> <button type="button" aria-label="Medical" class="mobile-dropdown-title"><span class="title">Medical</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/medical/imaging.html" class="nav-link">
  Medical imagery
</a></li><li class="dropdown-item"><!----> <a href="/fastai/medical/text.html" class="nav-link">
  Medical text
</a></li></ul></div></div> <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Getting Started" class="dropdown-title"><span class="title">Getting Started</span> <span class="arrow down"></span></button> <button type="button" aria-label="Getting Started" class="mobile-dropdown-title"><span class="title">Getting Started</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><!----> <a href="/fastai/quick_start.html" class="nav-link">
  Quick Start
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tutorials" class="dropdown-title"><span class="title">Tutorials</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tutorials" class="mobile-dropdown-title"><span class="title">Tutorials</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tutorial/overview.html" class="nav-link">
  Overview
</a></li><li class="dropdown-item"><h4>
          Beginners
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/vision.html" class="nav-link">
  Vision Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/text.html" class="nav-link">
  Text Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/tabular.html" class="nav-link">
  Tabular Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/colab.html" class="nav-link">
  Colab Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Intermediate
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/datablock.html" class="nav-link">
  Data Block Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/imagenette.html" class="nav-link">
  Imagenette Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/pets.html" class="nav-link">
  Pets Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/transformers.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  Transformers Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/tutorial/wikitext.html" class="nav-link">
  Wikitext Tutorial
</a></li></ul></li><li class="dropdown-item"><h4>
          Advanced
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/tutorial/siamese.html" class="nav-link">
  Siamese Tutorial
</a></li><li class="dropdown-subitem"><a href="/fastai/dev-setup.html" class="nav-link">
  Developer Guide
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Training" class="dropdown-title"><span class="title">Training</span> <span class="arrow down"></span></button> <button type="button" aria-label="Training" class="mobile-dropdown-title"><span class="title">Training</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/training/learner.html" class="nav-link">
  Training Loop
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/optimizer.html" class="nav-link">
  Optimizer
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/metrics.html" class="nav-link">
  Metrics
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/interpret.html" class="nav-link">
  Interpretation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/training/distributed.html" class="nav-link">
  Distributed
</a></li><li class="dropdown-item"><h4>
          Callbacks
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/callback/core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/schedule.html" class="nav-link">
  Schedulers
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/hook.html" class="nav-link">
  Hooks and callbacks
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/fp16.html" class="nav-link">
  Mixed precision
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/mixup.html" class="nav-link">
  Mixup
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/cutmix.html" class="nav-link">
  Cutmix
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/tracker.html" class="nav-link">
  Tracker
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/training.html" class="nav-link">
  Training
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/rnn.html" class="nav-link">
  RNN
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/data.html" class="nav-link">
  Data
</a></li><li class="dropdown-subitem"><a href="/fastai/callback/progress.html" class="nav-link">
  Progress
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Data" class="dropdown-title"><span class="title">Data</span> <span class="arrow down"></span></button> <button type="button" aria-label="Data" class="mobile-dropdown-title"><span class="title">Data</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/data/block.html" class="nav-link">
  Data Blocks
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/transforms.html" class="nav-link">
  Data Transforms
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/external.html" class="nav-link">
  Data External
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/core.html" class="nav-link">
  Data Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/data/load.html" class="nav-link">
  DataLoaders
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Core" class="dropdown-title"><span class="title">Core</span> <span class="arrow down"></span></button> <button type="button" aria-label="Core" class="mobile-dropdown-title"><span class="title">Core</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/torch_core.html" class="nav-link">
  PyTorch Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/layers.html" class="nav-link">
  Layers
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Vision" class="dropdown-title"><span class="title">Vision</span> <span class="arrow down"></span></button> <button type="button" aria-label="Vision" class="mobile-dropdown-title"><span class="title">Vision</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/vision/learner.html" class="nav-link">
  Vision Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/augment.html" class="nav-link">
  Vision Data Augmentation
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/data.html" class="nav-link">
  Vision Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/core.html" class="nav-link">
  Vision Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/utils.html" class="nav-link">
  Vision Utils
</a></li><li class="dropdown-item"><!----> <a href="/fastai/vision/widgets.html" class="nav-link">
  Vision Widgets
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/vision/models.xresnet.html" class="nav-link">
  XResNet
</a></li><li class="dropdown-subitem"><a href="/fastai/vision/models.unet.html" class="nav-link">
  UNet
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Text" class="dropdown-title"><span class="title">Text</span> <span class="arrow down"></span></button> <button type="button" aria-label="Text" class="mobile-dropdown-title"><span class="title">Text</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/text/core.html" class="nav-link">
  Text Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/data.html" class="nav-link">
  Text Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/text/learner.html" class="nav-link">
  Text Learner
</a></li><li class="dropdown-item"><h4>
          Models
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/fastai/text/models.core.html" class="nav-link">
  Core
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.awdlstm.html" class="nav-link">
  AWD LSTM
</a></li><li class="dropdown-subitem"><a href="/fastai/text/models.qrnn.html" class="nav-link">
  QRNN
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Tabular" class="dropdown-title"><span class="title">Tabular</span> <span class="arrow down"></span></button> <button type="button" aria-label="Tabular" class="mobile-dropdown-title"><span class="title">Tabular</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/tabular/core.html" class="nav-link">
  Tabular Core
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/data.html" class="nav-link">
  Tabular Data
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/learner.html" class="nav-link">
  Tabular Learner
</a></li><li class="dropdown-item"><!----> <a href="/fastai/tabular/model.html" class="nav-link">
  Tabular Model
</a></li><li class="dropdown-item"><!----> <a href="/fastai/collab.html" class="nav-link">
  Collab
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Medical" class="dropdown-title"><span class="title">Medical</span> <span class="arrow down"></span></button> <button type="button" aria-label="Medical" class="mobile-dropdown-title"><span class="title">Medical</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/fastai/medical/imaging.html" class="nav-link">
  Medical imagery
</a></li><li class="dropdown-item"><!----> <a href="/fastai/medical/text.html" class="nav-link">
  Medical text
</a></li></ul></div></div> <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Tutorial - Transformers</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/fastai/tutorial/transformers.html#importing-a-transformers-pretrained-model" class="sidebar-link">Importing a transformers pretrained model</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/fastai/tutorial/transformers.html#bridging-the-gap-with-fastai" class="sidebar-link">Bridging the gap with fastai</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/fastai/tutorial/transformers.html#preparing-the-data" class="sidebar-link">Preparing the data</a></li><li class="sidebar-sub-header"><a href="/fastai/tutorial/transformers.html#fine-tuning-the-model" class="sidebar-link">Fine-tuning the model</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="tutorial-transformers"><a href="#tutorial-transformers" class="header-anchor">#</a> Tutorial - Transformers</h1> <blockquote><p>An example of how to incorporate the transfomers library from HuggingFace with fastai</p></blockquote> <p>In this tutorial, we will see how we can use the fastai library to fine-tune a pretrained transformer model from the <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">transformers library<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> by HuggingFace. We will use the mid-level API to gather the data. Even if this tutorial is self contained, it might help to check the <a href="http://docs.fast.ai/tutorial.imagenette" target="_blank" rel="noopener noreferrer">imagenette tutorial<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> to have a second look on the mid-level API (with a gentle introduction using the higher level APIs) in computer vision.</p> <h2 id="importing-a-transformers-pretrained-model"><a href="#importing-a-transformers-pretrained-model" class="header-anchor">#</a> Importing a transformers pretrained model</h2> <p>First things first, we will need to install the transformers library. If you haven't done it yet, install the library:</p> <div class="language- extra-class"><pre class="language-text"><code>!pip install -Uq transformers
</code></pre></div><p>Then let's import what will need: we will fine-tune the GPT2 pretrained model and fine-tune on wikitext-2 here. For this, we need the <code>GPT2LMHeadModel</code> (since we want a language model) and the <code>GPT2Tokenizer</code> to prepare the data.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> GPT2LMHeadModel<span class="token punctuation">,</span> GPT2TokenizerFast
</code></pre></div><p>We can use several versions of this GPT2 model, look at the <a href="https://huggingface.co/transformers/pretrained_models.html" target="_blank" rel="noopener noreferrer">transformers documentation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> for more details. Here we will use the basic version (that already takes a lot of space in memory!) You can change the model used by changing the content of <code>pretrained_weights</code> (if it's not a GPT2 model, you'll need to change the classes used for the model and the tokenizer of course).</p> <div class="language-python extra-class"><pre class="language-python"><code>pretrained_weights <span class="token operator">=</span> <span class="token string">'gpt2'</span>
tokenizer <span class="token operator">=</span> GPT2TokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>pretrained_weights<span class="token punctuation">)</span>
model <span class="token operator">=</span> GPT2LMHeadModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>pretrained_weights<span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre></div><p>Before we move on to the fine-tuning part, let's have a look at this <code>tokenizer</code> and this <code>model</code>. The tokenizers in HuggingFace usually do the tokenization and the numericalization in one step (we ignore the padding warning for now):</p> <div class="language-python extra-class"><pre class="language-python"><code>ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'This is an example of text, and'</span><span class="token punctuation">)</span>
ids
</code></pre></div><div class="language- extra-class"><pre><code>[1212, 318, 281, 1672, 286, 2420, 11, 290]
</code></pre></div><p>Like fastai <a href="https://fastcore.fast.ai/transform#Transform" target="_blank" rel="noopener noreferrer"><code>Transform</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>s, the tokenizer has a <code>decode</code> method to give you back a text from ids:</p> <div class="language-python extra-class"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>ids<span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>'This is an example of text, and'
</code></pre></div><p>The model can be used to generate predictions (it is pretrained). It has a <code>generate</code> method that expects a batch of prompt, so we feed it our ids and add one batch dimension (there is a padding warning we can ignore as well):</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span>
preds <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence
</code></pre></div><p>The predictions, by default, are of length 20:</p> <div class="language-python extra-class"><pre class="language-python"><code>preds<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre></div><div class="language- extra-class"><pre><code>(torch.Size([1, 20]),
 tensor([1212,  318,  281, 1672,  286, 2420,   11,  290,  340,  338,  407,  257,
          922,  530,   13,  198,  198,  464,  717, 1517]))
</code></pre></div><p>We can use the decode method (that prefers a numpy array to a tensor):</p> <div class="language-python extra-class"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>&quot;This is an example of text, and it's not a good one.\n\nThe first thing&quot;
</code></pre></div><h2 id="bridging-the-gap-with-fastai"><a href="#bridging-the-gap-with-fastai" class="header-anchor">#</a> Bridging the gap with fastai</h2> <p>Now let's see how we can use fastai to fine-tune this model on wikitext-2, using all the training utilities (learning rate finder, 1cycle policy etc...). First, we import all the text utilities:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>text<span class="token punctuation">.</span><span class="token builtin">all</span> <span class="token keyword">import</span> <span class="token operator">*</span>
</code></pre></div><h3 id="preparing-the-data"><a href="#preparing-the-data" class="header-anchor">#</a> Preparing the data</h3> <p>Then we download the dataset (if not present), it comes as two csv files:</p> <div class="language-python extra-class"><pre class="language-python"><code>path <span class="token operator">=</span> untar_data<span class="token punctuation">(</span>URLs<span class="token punctuation">.</span>WIKITEXT_TINY<span class="token punctuation">)</span>
path<span class="token punctuation">.</span>ls<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>(#2) [Path('/home/jhoward/.fastai/data/wikitext-2/test.csv'),Path('/home/jhoward/.fastai/data/wikitext-2/train.csv')]
</code></pre></div><p>Let's have a look at what those csv files look like:</p> <div class="language-python extra-class"><pre class="language-python"><code>df_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'train.csv'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
df_valid <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'test.csv'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
df_train<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><div><style scoped="scoped">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;!--beforebegin--&gt;&lt;div class=&quot;language- extra-class&quot;&gt;&lt;!--afterbegin--&gt;&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!--beforeend--&gt;&lt;/div&gt;&lt;!--afterend--&gt;</style> <table border="1" class="dataframe"><thead><tr style="text-align:right;"><th></th> <th>0</th></tr></thead> <tbody><tr><th>0</th> <td>\n = 2013 – 14 York City F.C. season = \n \n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td></tr> <tr><th>1</th> <td>\n = Big Boy ( song ) = \n \n &quot; Big Boy &quot; &lt;unk&gt; &quot; I 'm A Big Boy Now &quot; was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including &quot; Big Boy &quot; . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td></tr> <tr><th>2</th> <td>\n = The Remix ( Lady Gaga album ) = \n \n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit...</td></tr> <tr><th>3</th> <td>\n = New Year 's Eve ( Up All Night ) = \n \n &quot; New Year 's Eve &quot; is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \n During Reagan ( Christina Applegate ) and Chris 's ( Will &lt;unk&gt; ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...</td></tr> <tr><th>4</th> <td>\n = Geopyxis carbonaria = \n \n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family &lt;unk&gt; . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf &lt;unk&gt; cup , &lt;unk&gt; &lt;unk&gt; cup , or pixie cup . The small , &lt;unk&gt; @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....</td></tr></tbody></table></div> <p>We gather all texts in one numpy array (since it will be easier to use this way with fastai):</p> <div class="language-python extra-class"><pre class="language-python"><code>all_texts <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>df_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_valid<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>To process this data to train a model, we need to build a <a href="https://fastcore.fast.ai/transform#Transform" target="_blank" rel="noopener noreferrer"><code>Transform</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> that will be applied lazily. In this case we might could do the pre-processing once and for all and only use the transform for decoding (we will see how just after), but the fast tokenizer from HuggingFace is, as its name indicates, fast, so it doesn't really impact performance to do it this way.</p> <p>In a fastai <a href="https://fastcore.fast.ai/transform#Transform" target="_blank" rel="noopener noreferrer"><code>Transform</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> you can define:</p> <ul><li>an <code>encodes</code> method that is applied when you call the transform (a bit like the <code>forward</code> method in a <code>nn.Module</code>)</li> <li>a <code>decodes</code> method that is applied when you call the <code>decode</code> method of the transform, if you need to decode anything for showing purposes (like converting ids to a text here)</li> <li>a <code>setups</code> method that sets some inner state of the <a href="https://fastcore.fast.ai/transform#Transform" target="_blank" rel="noopener noreferrer"><code>Transform</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> (not needed here so we skip it)</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TransformersTokenizer</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
    <span class="token keyword">def</span> <span class="token function">encodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        toks <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>toks<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">decodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> TitledStr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>Two comments on the code above:</p> <ul><li>in <code>encodes</code> we don't use the <code>tokenizer.encode</code> method since it does some additional preprocessing for the model after tokenizing and numericalizing (the part throwing a warning before). Here we don't need any post-processing so it's fine to skip it.</li> <li>in <code>decodes</code> we return a <a href="/fastai/torch_core.html#TitledStr"><code>TitledStr</code></a> object and not just a plain string. That's a fastai class that adds a <code>show</code> method to the string, which will allow us to use all the fastai show methods.</li></ul> <p>You can then group your data with this <a href="https://fastcore.fast.ai/transform#Transform" target="_blank" rel="noopener noreferrer"><code>Transform</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> using a <a href="/fastai/data.core.html#TfmdLists"><code>TfmdLists</code></a>. It has an s in its name because it contains the training and validation set. We indicate the indices of the training set and the validation set with <code>splits</code> (here all the first indices until <code>len(df_train)</code> and then all the remaining indices):</p> <div class="language-python extra-class"><pre class="language-python"><code>splits <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>range_of<span class="token punctuation">(</span>df_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>all_texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
tls <span class="token operator">=</span> TfmdLists<span class="token punctuation">(</span>all_texts<span class="token punctuation">,</span> TransformersTokenizer<span class="token punctuation">(</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span> splits<span class="token operator">=</span>splits<span class="token punctuation">,</span> dl_type<span class="token operator">=</span>LMDataLoader<span class="token punctuation">)</span>
</code></pre></div><p>We specify <code>dl_type=LMDataLoader</code> for when we will convert this <a href="/fastai/data.core.html#TfmdLists"><code>TfmdLists</code></a> to <a href="/fastai/data.core.html#DataLoaders"><code>DataLoaders</code></a>: we will use an <a href="/fastai/text.data.html#LMDataLoader"><code>LMDataLoader</code></a> since we have a language modeling problem, not the usual fastai <a href="/fastai/data.core.html#TfmdDL"><code>TfmdDL</code></a>.</p> <p>In a <a href="/fastai/data.core.html#TfmdLists"><code>TfmdLists</code></a> you can access to the elements of the training or validation set quite easily:</p> <div class="language-python extra-class"><pre class="language-python"><code>tls<span class="token punctuation">.</span>train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tls<span class="token punctuation">.</span>valid<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre></div><div class="language- extra-class"><pre><code>(tensor([220, 198, 796,  ..., 198, 220, 198]),
 tensor([220, 198, 796,  ..., 198, 220, 198]))
</code></pre></div><p>They both look the same but that just begins they begin and end the same way, we can see the shape are different:</p> <div class="language-python extra-class"><pre class="language-python"><code>tls<span class="token punctuation">.</span>tfms<span class="token punctuation">(</span>tls<span class="token punctuation">.</span>train<span class="token punctuation">.</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span> tls<span class="token punctuation">.</span>tfms<span class="token punctuation">(</span>tls<span class="token punctuation">.</span>valid<span class="token punctuation">.</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape
</code></pre></div><div class="language- extra-class"><pre><code>(torch.Size([4576]), torch.Size([1485]))
</code></pre></div><p>And we can have a look at both decodes using <a href="/fastai/data.core.html#show_at"><code>show_at</code></a>:</p> <div class="language-python extra-class"><pre class="language-python"><code>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>
</code></pre></div><p>The fastai library expects the data to be assembled in a <a href="/fastai/data.core.html#DataLoaders"><code>DataLoaders</code></a> object (something that has a training and validation dataloader). We can get one by using the <code>dataloaders</code> method. We just have to specify a batch size and a sequence length. Since the GPT2 model was trained with sequences of size 1024, we use this sequence length (it's a stateless model, so it will change the perplexity if we use less):</p> <div class="language-python extra-class"><pre class="language-python"><code>bs<span class="token punctuation">,</span>sl <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span><span class="token number">1024</span>
dls <span class="token operator">=</span> tls<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>bs<span class="token operator">=</span>bs<span class="token punctuation">,</span> seq_len<span class="token operator">=</span>sl<span class="token punctuation">)</span>
</code></pre></div><p>Note that you may have to reduce the batch size depending on your GPU RAM.</p> <p>In fastai, as soo as we have a <a href="/fastai/data.core.html#DataLoaders"><code>DataLoaders</code></a>, we can use <code>show_batch</code> to have a look at the data (here texts for inputs, and the same text shifted by one token to the right for validation):</p> <div class="language-python extra-class"><pre class="language-python"><code>dls<span class="token punctuation">.</span>show_batch<span class="token punctuation">(</span>max_n<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre></div><table border="1" class="dataframe"><thead><tr style="text-align:right;"><th></th> <th>text</th> <th>text_</th></tr></thead> <tbody><tr><th>0</th> <td>\n = Ten Commandments in Catholic theology = \n \n The Ten Commandments are a series of religious and moral &lt;unk&gt; that are recognized as a moral foundation in several of the Abrahamic religions, including Catholicism. As described in the Old Testament books Exodus and &lt;unk&gt;, the Commandments form part of a covenant offered by God to the Israelites to free them from the spiritual slavery of sin. According to the Catechism of the Catholic Church — the official &lt;unk&gt; of the Catholic Church's Christian beliefs — the Commandments are considered essential for spiritual good health and growth, and serve as the basis for Catholic social justice. A review of the Commandments is one of the most common types of examination of conscience used by Catholics before receiving the sacrament of &lt;unk&gt;. \n The Commandments appear in the earliest Church writings ; the Catechism states that they have &quot;</td> <td>\n = Ten Commandments in Catholic theology = \n \n The Ten Commandments are a series of religious and moral &lt;unk&gt; that are recognized as a moral foundation in several of the Abrahamic religions, including Catholicism. As described in the Old Testament books Exodus and &lt;unk&gt;, the Commandments form part of a covenant offered by God to the Israelites to free them from the spiritual slavery of sin. According to the Catechism of the Catholic Church — the official &lt;unk&gt; of the Catholic Church's Christian beliefs — the Commandments are considered essential for spiritual good health and growth, and serve as the basis for Catholic social justice. A review of the Commandments is one of the most common types of examination of conscience used by Catholics before receiving the sacrament of &lt;unk&gt;. \n The Commandments appear in the earliest Church writings ; the Catechism states that they have &quot; occupied</td></tr> <tr><th>1</th> <td>@ 8 million ( US $ 7 @.@ 0 million ) in 35 days. The film completed a 50 @-@ day run in 302 centres on 18 September 2009. By then, the film had collected ₹ 650 million ( US $ 9 @.@ 7 million ) and stood strong. \n The film completed its 100 @-@ day run in 223 centres and grossed over ₹ 1 @.@ 25 billion ( US $ 19 million ) without satellite and audio rights. By then it had surpassed &lt;unk&gt;'s Sivaji ( 2007 ), which grossed ₹ 650 million ( US $ 9 @.@ 7 million ) in Tamil Nadu, and stood second to &lt;unk&gt; ( 2008 ), which reached ₹ 2 billion ( US $ 30 million ). The film completed a 175 @-@ day run in 3 centres and, by then, collected a share of ₹ 580 million ( US $ 8</td> <td>8 million ( US $ 7 @.@ 0 million ) in 35 days. The film completed a 50 @-@ day run in 302 centres on 18 September 2009. By then, the film had collected ₹ 650 million ( US $ 9 @.@ 7 million ) and stood strong. \n The film completed its 100 @-@ day run in 223 centres and grossed over ₹ 1 @.@ 25 billion ( US $ 19 million ) without satellite and audio rights. By then it had surpassed &lt;unk&gt;'s Sivaji ( 2007 ), which grossed ₹ 650 million ( US $ 9 @.@ 7 million ) in Tamil Nadu, and stood second to &lt;unk&gt; ( 2008 ), which reached ₹ 2 billion ( US $ 30 million ). The film completed a 175 @-@ day run in 3 centres and, by then, collected a share of ₹ 580 million ( US $ 8</td></tr></tbody></table> <p>Another way to gather the data is to preprocess the texts once and for all and only use the transform to decode the tensors to texts:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    toks <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tensor<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>toks<span class="token punctuation">)</span><span class="token punctuation">)</span>

tokenized <span class="token operator">=</span> <span class="token punctuation">[</span>tokenize<span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> progress_bar<span class="token punctuation">(</span>all_texts<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre></div><div><style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style> <progress value="662" max="662" style="width:300px;height:20px;vertical-align:middle;"></progress>
  100.00% [662/662 00:12&lt;00:00]
</div> <p>Now we change the previous <a href="/fastai/text.core.html#Tokenizer"><code>Tokenizer</code></a> like this:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TransformersTokenizer</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
    <span class="token keyword">def</span> <span class="token function">encodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> Tensor<span class="token punctuation">)</span> <span class="token keyword">else</span> tokenize<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">decodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> TitledStr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>In the <code>encodes</code> method, we still account for the case where we get something that's not already tokenized, just in case we were to build a dataset with new texts using this transform.</p> <div class="language-python extra-class"><pre class="language-python"><code>tls <span class="token operator">=</span> TfmdLists<span class="token punctuation">(</span>tokenized<span class="token punctuation">,</span> TransformersTokenizer<span class="token punctuation">(</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span> splits<span class="token operator">=</span>splits<span class="token punctuation">,</span> dl_type<span class="token operator">=</span>LMDataLoader<span class="token punctuation">)</span>
dls <span class="token operator">=</span> tls<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>bs<span class="token operator">=</span>bs<span class="token punctuation">,</span> seq_len<span class="token operator">=</span>sl<span class="token punctuation">)</span>
</code></pre></div><p>And we can check it still works properly for showing purposes:</p> <div class="language-python extra-class"><pre class="language-python"><code>dls<span class="token punctuation">.</span>show_batch<span class="token punctuation">(</span>max_n<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre></div><table border="1" class="dataframe"><thead><tr style="text-align:right;"><th></th> <th>text</th> <th>text_</th></tr></thead> <tbody><tr><th>0</th> <td>\n = New Year's Eve ( Up All Night ) = \n \n &quot; New Year's Eve &quot; is the twelfth episode of the first season of the American comedy television series Up All Night. The episode originally aired on NBC in the United States on January 12, 2012. It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller. The episode also featured a guest appearance from Jason Lee as Chris and Reagan's neighbor and Ava's boyfriend, Kevin. \n During Reagan ( Christina Applegate ) and Chris's ( Will &lt;unk&gt; ) first New Year's Eve game night, Reagan's competitiveness comes out causing Chris to become embarrassed. Meanwhile, Missy ( Jennifer Hall ) brings an unexpected date along to the party and, Kevin ( Jason Lee ) starts to feel as though Ava ( Maya Rudolph ) may be &lt;unk&gt; of him. \n &quot; New Year's</td> <td>\n = New Year's Eve ( Up All Night ) = \n \n &quot; New Year's Eve &quot; is the twelfth episode of the first season of the American comedy television series Up All Night. The episode originally aired on NBC in the United States on January 12, 2012. It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller. The episode also featured a guest appearance from Jason Lee as Chris and Reagan's neighbor and Ava's boyfriend, Kevin. \n During Reagan ( Christina Applegate ) and Chris's ( Will &lt;unk&gt; ) first New Year's Eve game night, Reagan's competitiveness comes out causing Chris to become embarrassed. Meanwhile, Missy ( Jennifer Hall ) brings an unexpected date along to the party and, Kevin ( Jason Lee ) starts to feel as though Ava ( Maya Rudolph ) may be &lt;unk&gt; of him. \n &quot; New Year's Eve</td></tr> <tr><th>1</th> <td>its peak intensity on August 28 as a Category 2 hurricane with maximum sustained winds of 100 mph ( 160 km / h ). At the same time, a reconnaissance aircraft reported a minimum barometric pressure of 991 mbar ( hPa ; 29 @.@ 27 inHg ) in the storm's eye as Edith made its closest pass to Bermuda. The hurricane began to gradually weaken after it passed east of the island, before becoming extratropical on August 31. The cyclone would later make a clockwise loop before dissipating completely late on September 3. Although Edith remained at sea, it was suspected that the hurricane may have caused the loss of the pleasure yacht &lt;unk&gt; IV, after it separated from its &lt;unk&gt;. \n \n = = = Tropical Storm Five = = = \n \n A weak disturbance was first observed near Grand Cayman on August 23, gaining tropical storm</td> <td>peak intensity on August 28 as a Category 2 hurricane with maximum sustained winds of 100 mph ( 160 km / h ). At the same time, a reconnaissance aircraft reported a minimum barometric pressure of 991 mbar ( hPa ; 29 @.@ 27 inHg ) in the storm's eye as Edith made its closest pass to Bermuda. The hurricane began to gradually weaken after it passed east of the island, before becoming extratropical on August 31. The cyclone would later make a clockwise loop before dissipating completely late on September 3. Although Edith remained at sea, it was suspected that the hurricane may have caused the loss of the pleasure yacht &lt;unk&gt; IV, after it separated from its &lt;unk&gt;. \n \n = = = Tropical Storm Five = = = \n \n A weak disturbance was first observed near Grand Cayman on August 23, gaining tropical storm strength</td></tr></tbody></table> <h3 id="fine-tuning-the-model"><a href="#fine-tuning-the-model" class="header-anchor">#</a> Fine-tuning the model</h3> <p>The HuggingFace model will return a tuple in outputs, with the actual predictions and some additional activations (should we want to use them is some regularization scheme). To work inside the fastai training loop, we will need to drop those using a <a href="/fastai/callback.core.html#Callback"><code>Callback</code></a>: we use those to alter the behavior of the training loop.</p> <p>Here we need to write the event <code>after_pred</code> and replace <code>self.learn.pred</code> (which contains the predictions that will be passed to the loss function) by just its first element. In callbacks, there is a shortcut that lets you access any of the underlying <a href="/fastai/learner.html#Learner"><code>Learner</code></a> attribute so we can write <code>self.pred[0]</code> instead of <code>self.learn.pred[0]</code>. That shorcut only works for read access, not write, so we have to write <code>self.learn.pred</code> on the right side (otherwise we would set a <code>pred</code> attribute in the <a href="/fastai/callback.core.html#Callback"><code>Callback</code></a>).</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">DropOutput</span><span class="token punctuation">(</span>Callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">after_pred</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>learn<span class="token punctuation">.</span>pred <span class="token operator">=</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre></div><p>Of course we could make this a bit more complex and add some penalty to the loss using the other part of the tuple of predictions, like the <a href="/fastai/callback.rnn.html#RNNRegularizer"><code>RNNRegularizer</code></a>.</p> <p>Now, we are ready to create our <a href="/fastai/learner.html#Learner"><code>Learner</code></a>, which is a fastai object grouping data, model and loss function and handles model training or inference. Since we are in a language model setting, we pass perplexity as a metric, and we need to use the callback we just defined. Lastly, we use mixed precision to save every bit of memory we can (and if you have a modern GPU, it will also make training faster):</p> <div class="language-python extra-class"><pre class="language-python"><code>learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cbs<span class="token operator">=</span><span class="token punctuation">[</span>DropOutput<span class="token punctuation">]</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span>Perplexity<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_fp16<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>We can check how good the model is without any fine-tuning step (spoiler alert, it's pretty good!)</p> <div class="language-python extra-class"><pre class="language-python"><code>learn<span class="token punctuation">.</span>validate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>(#2) [3.2425637245178223,25.599266052246094]
</code></pre></div><p>This lists the validation loss and metrics (so 26.6 as perplexity is kind of amazing).</p> <p>Now that we have a <a href="/fastai/learner.html#Learner"><code>Learner</code></a> we can use all the fastai training loop capabilities: learning rate finder, training with 1cycle etc...</p> <div class="language-python extra-class"><pre class="language-python"><code>learn<span class="token punctuation">.</span>lr_find<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>SuggestedLRs(lr_min=0.00831763744354248, lr_steep=0.0691830962896347)
</code></pre></div><p><img src="output_62_2.png" alt="png"></p> <p>The learning rate finder curve suggests picking something between 1e-4 and 1e-3.</p> <div class="language-python extra-class"><pre class="language-python"><code>learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><table border="1" class="dataframe"><thead><tr style="text-align:left;"><th>epoch</th> <th>train_loss</th> <th>valid_loss</th> <th>perplexity</th> <th>time</th></tr></thead> <tbody><tr><td>0</td> <td>3.646031</td> <td>3.244000</td> <td>25.636072</td> <td>02:44</td></tr></tbody></table> <p>Now with just one epoch of fine-tuning and not much regularization, our model did not really improve since it was already amazing. To have a look at some generated texts, let's take a prompt that looks like a wikipedia article:</p> <div class="language-python extra-class"><pre class="language-python"><code>df_valid<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><div><style scoped="scoped">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;!--beforebegin--&gt;&lt;div class=&quot;language- extra-class&quot;&gt;&lt;!--afterbegin--&gt;&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!--beforeend--&gt;&lt;/div&gt;&lt;!--afterend--&gt;</style> <table border="1" class="dataframe"><thead><tr style="text-align:right;"><th></th> <th>0</th></tr></thead> <tbody><tr><th>0</th> <td>\n = Tropical Storm &lt;unk&gt; ( 2008 ) = \n \n Tropical Storm &lt;unk&gt; was the tenth tropical storm of the 2008 Atlantic hurricane season . &lt;unk&gt; developed out of a strong tropical wave which moved off the African coast on August 31 . The wave quickly became organized and was declared Tropical Depression Ten while located 170 mi ( 270 km ) to the south @-@ southeast of the Cape Verde Islands on September 2 . The depression was quickly upgraded to Tropical Storm &lt;unk&gt; around noon the same day . Over the next several days , &lt;unk&gt; moved in a general west @-@ northwest direction and reached its peak...</td></tr></tbody></table></div> <p>Article seems to begin with new line and the title between = signs, so we will mimic that:</p> <div class="language-python extra-class"><pre class="language-python"><code>prompt <span class="token operator">=</span> <span class="token string">&quot;\n = Unicorn = \n \n A unicorn is a magical creature with a rainbow tail and a horn&quot;</span>
</code></pre></div><p>The prompt needs to be tokenized and numericalized, so we use the same function as before to do this, before we use the <code>generate</code> method of the model.</p> <div class="language-python extra-class"><pre class="language-python"><code>prompt_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
inp <span class="token operator">=</span> tensor<span class="token punctuation">(</span>prompt_ids<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
inp<span class="token punctuation">.</span>shape
</code></pre></div><div class="language- extra-class"><pre><code>torch.Size([1, 21])
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>preds <span class="token operator">=</span> learn<span class="token punctuation">.</span>model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>inp<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">1.5</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre><code>'\n = Unicorn = \n \n A unicorn is a magical creature with a rainbow tail and a horn on its head.\n\nA unicorn can fly at speeds of up to 100 miles per hour'
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/fastai/assets/js/app.e4c088e4.js" defer></script><script src="/fastai/assets/js/2.f1c4f916.js" defer></script><script src="/fastai/assets/js/63.a3aa571a.js" defer></script>
  </body>
</html>
